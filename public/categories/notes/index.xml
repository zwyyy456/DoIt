<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on My New Hugo Site</title>
    <link>http://localhost:1313/categories/notes/</link>
    <description>Recent content in Notes on My New Hugo Site</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Jun 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>计算机教育缺失的一课：Git</title>
      <link>http://localhost:1313/posts/tech/missing-semester-git.zh/</link>
      <pubDate>Sun, 16 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/tech/missing-semester-git.zh/</guid>
      <description>版本控制系统介绍 版本控制系统 (VCSs) 是一类用于追踪源代码（或其他文件、文件夹）改动的工具。顾名思义，这些工具可以帮助我们管理代码的修改历史；不仅如此，它还可以让协作编码变得更方便。VCS 通过一系列的快照将某个文件夹及其内容保存了起来，每个快照都包含了文件或文件夹的完整状态。同时它还维护了快照创建者的信息以及每个快照的相关信息等等。&#xA;版本控制系统的事实标准是 Git。&#xA;Git 的许多操作或者说命令看起来非常奇怪，但 Git 的底层设计与思想非常优雅，因此，从 Git 的数据模型开始学习 Git，自底向上，最后再学习 Git 的接口或者说命令，会比较容易让人理解 Git 的命令以及 Git 是如何操作数据模型的。&#xA;Git 的数据模型 Git 将项目的根目录（顶层目录）中的文件夹与文件作为集合，通过这一系列集合的快照来管理项目历史记录。在 Git 的术语中，文件被称为 Blob（数据对象），即一组数据，目录则是被称为 tree。tree 的名称与另一个 tree 又或者文件相对应。&#xA;把目录视为 tree，那么子目录就是 subtree，目录下的文件就是 tree 的子节点。&#xA;一棵 tree 看起来可能是这样的：&#xA;&amp;lt;root&amp;gt; (tree) | +- foo (tree) | | | + bar.txt (blob, contents = &amp;#34;hello world&amp;#34;) | +- baz.txt (blob, contents = &amp;#34;git is wonderful&amp;#34;) Git 历史记录建模：关联快照 Git 中的 object 可以分为 blob、tree、commit 三类，每次我们执行 git commit 时，都会创建一个 commit 对象，又或者说对当前的 work directory 的 snapshot。</description>
    </item>
    <item>
      <title>计算机常用术语中英文对比</title>
      <link>http://localhost:1313/posts/tech/cs-zh-en-translation.zh/</link>
      <pubDate>Sat, 15 Jun 2024 16:19:53 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/cs-zh-en-translation.zh/</guid>
      <description>前言 在计算机科学中，很多专业术语或者名词的初始版本都是英文的，之后会被翻译成中文而引入国内。然而，个人看来，许多专业名词的中文翻译，看起来都非常奇怪，反而不如其原始的英文表述好理解，故本文列出笔者常见的一些计算机专业术语以及它的英文版本，以供查阅&#xA;术语列表 中文版本 英文版本 个人理解 快照 snapshot 在某个特定时刻，对系统、数据或者文件的状态进行捕捉与记录从而生成的副本，功能上类似备份 会话 session 一段时间内，用户与系统之间的交互或者连接状态 接口 interface 也许可以理解为暴露出来供用户（开发者）调用的函数？ </description>
    </item>
    <item>
      <title>计算机教育缺失的一课：命令行环境</title>
      <link>http://localhost:1313/posts/tech/missing-semester-command-line.zh/</link>
      <pubDate>Sat, 15 Jun 2024 15:18:13 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/missing-semester-command-line.zh/</guid>
      <description>任务控制 信号与终止进程 shell 会使用 unix 提供的信号机制来进行进程之间的通信，当一个进程接收到信号时，它会停止执行原来的任务、处理该信号、并基于该信号传递的信息来改变任务的执行，可以认为信号是一种 软件中断。&#xA;下面这个 python 程序演示了捕获 SIGINT 信号并忽略该信号，即这个程序在收到 SIGINT 信号时，不会终止程序，我们需要使用 SIGQUIT 信号来停止这个程序，可以通过 &amp;lt;C-\&amp;gt; 来发送该信号。&#xA;#!/usr/bin/env python import signal, time def handler(signum, time): print(&amp;#34;\nI got a SIGINT, but I am not stopping&amp;#34;) signal.signal(signal.SIGINT, handler) i = 0 while True: time.sleep(.1) print(&amp;#34;\r{}&amp;#34;.format(i), end=&amp;#34;&amp;#34;) i += 1 运行该程序，向该程序发送两次 SIGINT，然后发送一次 SIGQUIT，程序反应如下：&#xA;zwyyy in 🌐 d3855u in ~/missing-semester 13s ❯ python3 sig.py 28^C I got a SIGINT, but I am not stopping 53^C I got a SIGINT, but I am not stopping 63^\zsh: quit python3 sig.</description>
    </item>
    <item>
      <title>计算机教育缺失的一课：数据整理</title>
      <link>http://localhost:1313/posts/tech/missing-semester-data-organize.zh/</link>
      <pubDate>Fri, 14 Jun 2024 19:26:09 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/missing-semester-data-organize.zh/</guid>
      <description>前言 您是否曾经有过这样的需求，将某种格式存储的数据转换成另外一种格式? 肯定有过，对吧！ 这也正是我们这节课所要讲授的主要内容。具体来讲，我们需要不断地对数据进行处理，直到得到我们想要的最终结果。&#xA;在之前的课程中，其实我们已经接触到了一些数据整理的基本技术。可以这么说，每当您使用管道运算符的时候，其实就是在进行某种形式的数据整理。&#xA;例如这样一条命令 journalctl | grep -i intel，它会找到所有包含intel(不区分大小写)的系统日志。您可能并不认为这是数据整理，但是它确实将某种形式的数据（全部系统日志）转换成了另外一种形式的数据（仅包含intel的日志）。大多数情况下，数据整理需要您能够明确哪些工具可以被用来达成特定数据整理的目的，并且明白如何组合使用这些工具。&#xA;让我们从头讲起。既然是学习数据整理，那有两样东西自然是必不可少的：用来整理的数据以及相关的应用场景。日志处理通常是一个比较典型的使用场景，因为我们经常需要在日志中查找某些信息，这种情况下通读日志是不现实的。现在，让我们研究一下系统日志，看看哪些用户曾经尝试过登录我们的服务器：&#xA;ssh myserver journalctl 内容太多了。现在让我们把涉及 sshd 的信息过滤出来：&#xA;ssh myserver journalctl | grep sshd 注意，这里我们使用管道将一个远程服务器上的文件传递给本机的 grep 程序！ ssh 太牛了，下一节课我们会讲授命令行环境，届时我们会详细讨论 ssh 的相关内容。此时我们打印出的内容，仍然比我们需要的要多得多，读起来也非常费劲。我们来改进一下：&#xA;ssh myserver &amp;#39;journalctl | grep sshd | grep &amp;#34;Disconnected from&amp;#34;&amp;#39; | less 多出来的引号是什么作用呢？这么说吧，我们的日志是一个非常大的文件，把这么大的文件流直接传输到我们本地的电脑上再进行过滤是对流量的一种浪费。因此我们采取另外一种方式，我们先在远端机器上过滤文本内容，然后再将结果传输到本机。 less 为我们创建来一个文件分页器，使我们可以通过翻页的方式浏览较长的文本。为了进一步节省流量，我们甚至可以将当前过滤出的日志保存到文件中，这样后续就不需要再次通过网络访问该文件了：&#xA;$ ssh myserver &amp;#39;journalctl | grep sshd | grep &amp;#34;Disconnected from&amp;#34;&amp;#39; &amp;gt; ssh.log $ less ssh.log 过滤结果中仍然包含不少没用的数据。我们有很多办法可以删除这些无用的数据，但是让我们先研究一下 sed 这个非常强大的工具。&#xA;sed 是一个基于文本编辑器ed构建的&amp;quot;流编辑器&amp;quot; 。在 sed 中，您基本上是利用一些简短的命令来修改文件，而不是直接操作文件的内容（尽管您也可以选择这样做）。相关的命令行非常多，但是最常用的是 s，即替换命令，例如我们可以这样写：</description>
    </item>
    <item>
      <title>计算机教育缺失的一课：编辑器（Vim）</title>
      <link>http://localhost:1313/posts/tech/missing-semester-editor-vim.zh/</link>
      <pubDate>Fri, 14 Jun 2024 16:55:19 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/missing-semester-editor-vim.zh/</guid>
      <description>编辑模式 Vim 的符号说明，对于 Ctlr+v 的组合键，可能有 ^V、Ctrl-v、&amp;lt;C-v&amp;gt; 三种表达方式。&#xA;Vim 的设计以大多数时间都花在阅读、浏览和进行少量编辑改动为基础，因此它具有多种操作模式：&#xA;正常模式：在文件中四处移动光标进行修改 插入模式：插入文本 替换模式：替换文本 可视化模式（一般，行，块）：选中文本块 命令模式：用于执行命令 正常模式即 normal 模式，我更习惯叫 normal 模式。&#xA;Vim 的模式：&#xA;normal &amp;lt;-&amp;gt; insert replace visual command-line 在 normal 模式下，按下 v 可以进入可视（一般）模式，按下 V 则可以进入可视（行）模式，而 &amp;lt;C-v&amp;gt; 则会进入可视（方块）模式。&#xA;buffer，window，tab vim 具有多个 tab（标签），每个 tab 可以包含多个 window，每个 window 对应一个 buffer，而同一个 buffer 可能由多个 window 打开。&#xA;:q 实际上只是关闭当前窗口，假设 vim 已经没有打开的窗口了，那么才会退出 vim。&#xA;命令模式 在 normal 模式下按下 : 可以进入命令模式，这个模式下，可以打开、保存、关闭文件，以及退出 Vim。&#xA;:q 退出（关闭窗口） :w 保存（写） :wq 保存然后退出 :e {文件名} 打开要编辑的文件 :ls 显示打开的缓存 :help {标题} 打开帮助文档 :help :w 打开 :w 命令的帮助文档 :help w 打开 w 移动的帮助文档 移动光标 在 normal 模式下，可以利用移动命令在 buffer 中移动光标，在 Vim 中，移动也被称为“名词”，与编辑命令（i、o）等相对应。</description>
    </item>
    <item>
      <title>计算机教育缺失的一课：Shell 工具与脚本</title>
      <link>http://localhost:1313/posts/tech/missing-semester-shell.zh/</link>
      <pubDate>Thu, 09 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/tech/missing-semester-shell.zh/</guid>
      <description>$ 符号的功能 Shell 中，$ 符号可以与数字或者其他符号组合在一起表示特殊的值或者变量，如下：&#xA;#!/bin/bash echo $0 # $0 用于获取当前脚本文件名名称 echo &amp;#34;The first parameter: $1&amp;#34; # $1 表示第一个参数 echo &amp;#34;The eleventh parameter: ${11}2&amp;#34; echo &amp;#34;The eleventh parameter: ${11}x&amp;#34; echo &amp;#34;The eleventh parameter: $11x&amp;#34; echo &amp;#34;The eleventh parameter: $12&amp;#34; tmp=&amp;#34;hello&amp;#34; echo &amp;#34;$tmp world&amp;#34; 将以上脚本文件命名为 test.sh 并执行 bash test.sh 1 2 3 4 5 6 7 8 9 10 13 14，输出如下：&#xA;test.sh The first parameter: 1 The eleventh parameter: 132 The eleventh parameter: 13x The eleventh parameter: 11x The eleventh parameter: 12 hello wolrd 这是因为，只有 $n 才能表示第 n 个参数（n 为单个数字），如果想表示第 11 个参数，就必须使用 ${11}（加上大括号）来表示，bash 会将 $12 处理为名为 12 的变量。</description>
    </item>
    <item>
      <title>Json 快速入门</title>
      <link>http://localhost:1313/posts/tech/json-startup.zh/</link>
      <pubDate>Sat, 04 May 2024 10:10:30 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/json-startup.zh/</guid>
      <description>简介 Json 格式的全称为 JavaScript Object Notation，是一种起源于编程语言 JavaScript 的序列化数据格式，其特点在于，可以通过特定的文本格式表达一定程度的复杂数据，被广泛应用于其他编程语言中。&#xA;六个构造字符 Json 有六种有效符号，如下：&#xA;符号 名称 [ 左方括号 ] 右方括号 { 左花括号 } 右花括号 , 逗号 : 冒号 在这些符号之间的空格与换行在 Json 中没有实际意义，一般用于使 Json 代码更加规整。注意，Json 标准中无法表示注释。&#xA;五种数据类型 Json 中存在 5 种数据类型，分别是 数字、字符串、数组、对象、字面名（也可以理解为保留值）。&#xA;数字 数字是最基础的数据类型，可以是一个整数、也可以是一个小数&#xA;1234, 12.34 字符串 类似其他编程语言中的字符串。&#xA;&amp;#34;Json&amp;#34;, &amp;#34;中文&amp;#34; 数组 数组表示一串有固定的顺序的值，相比起 C++ 中的数组，Json 中的数组中的值的数据类型可以不同，数组中的值的元素类型也可以是 数组 或者 对象。&#xA;数组的格式如下：以 [ 作为起始，以 ] 作为结束，数组中的值之间以 , 分隔。&#xA;[ 12345, &amp;#34;start&amp;#34;, [&amp;#34;end&amp;#34;], {&amp;#34;123&amp;#34;: &amp;#34;45&amp;#34;} ] 对象 对象可以简单理解为一系列的键值对。&#xA;对象基本格式是以 { 为起始，以 } 作为结束，每个键值对以 , 进行分割，键值对中的键与值利用 : 进行分隔。</description>
    </item>
    <item>
      <title>Web Day12：实现主从 Reactor 多线程模式</title>
      <link>http://localhost:1313/posts/tech/web-day12.zh/</link>
      <pubDate>Sun, 19 Nov 2023 13:00:39 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/web-day12.zh/</guid>
      <description>前言 在 Day11 中，我们实现了一种最容易想到的 Reactor 多线程模式，即将每个 Channel 的任务分配给一个线程执行。&#xA;这个模式逻辑上有不少问题，例如线程池由 EventLoop 来持有，按理来说应该由 Server 类来管理，这是受到了 Channel 类的限制，Channel 类仅有 EventLoop 成员。&#xA;主从 Reactor 模式 主从 Reactor 模式有以下几个特点：&#xA;服务器一般只有一个 main reactor，可以有很多个 sub reactor； 服务器管理一个线程池，每个线程对应一个 sub reactor，每个 sub reactor 负责一部分 Connections 的事件循环，事件执行也在这个线程完成； main reactor 只负责 Acceptor 建立新连接，然后将这个连接分配给一个 sub Reactor。 Server 成员 /todo，测试 accept 和 connect 的时候区分非阻塞与阻塞&#xA;Server 的成员包括一个 main_reactor 和 多个 sub_reactors，每个 sub_reactor 对应一个独有的 EventLoop，每个 sub_reactor 由一个线程负责。这就是所谓的 One Loop per Thread。&#xA;class Server { private: EventLoop *main_reactor_; Acceptor *acceptor_; std::map&amp;lt;int, Connection *&amp;gt; connections_; std::vector&amp;lt;EventLoop *&amp;gt; sub_reactors_; ThreadPool *thpool_; public: Server(EventLoop *evl); ~Server(); void HandleReadEvent(int fd); void NewConn(Socket *serv_sock); void DeleteConn(int sockfd); }; main reactor 的工作流程 Server 创建的时候，会利用 main 函数的 loop 来初始化 Server，并利用 loop 来初始化 main_reactor_，和 acceptor_。 acceptor_ 会有绑定了服务器 ip 和端口的 socket。初始化 acceptor_ 的时候，会将 acceptor_-&amp;gt;new_conn_callback_ 注册为 Server::NewConn(Socket *clnt_sock)，当有连接时，acceptor_ 调用 Acceptor::AcceptConn()，该函数会调用 Socket::Accept(InetAddress *) 来接受连接，以及调用 new_conn_callback_(clnt_sock)，实际上就是调用 Server::NewConn(Socket *clnt_sock)。</description>
    </item>
    <item>
      <title>Web Day11：完成线程池以及加入一个简单的测试程序</title>
      <link>http://localhost:1313/posts/tech/web-day11.zh/</link>
      <pubDate>Sat, 18 Nov 2023 19:40:26 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/web-day11.zh/</guid>
      <description>需要完善的地方 Day10 中，我们添加了一个简单的线程池，一个完整的 Reactor 模型已经成型。但这个线程池存在的问题还比较多，例如任务队列的取出、添加都存在拷贝，性能较差，只能用于学习。&#xA;正确操作应该使用右值移动、完美转发等来阻止拷贝。&#xA;另外，线程池只能接受 std::function&amp;lt;void()&amp;gt; 类型的函数，所以函数需要使用 Lambda 表达式来创建，或者 std::bind()，且无法得到返回值。&#xA;利用模板 class ThreadPool { private: std::vector&amp;lt;std::thread&amp;gt; threads_; std::queue&amp;lt;std::function&amp;lt;void()&amp;gt;&amp;gt; tasks_; std::mutex tasks_mtx_; std::condition_variable cv_; bool stop_; public: explicit ThreadPool(int size = 8); ~ThreadPool(); template &amp;lt;class F, class... Args&amp;gt; auto add_task(F &amp;amp;&amp;amp;f, Args &amp;amp;&amp;amp;...args) -&amp;gt; std::future&amp;lt;typename std::result_of&amp;lt;F(Args...)&amp;gt;::type&amp;gt;; }; template &amp;lt;class F, class... Args&amp;gt; auto ThreadPool::add_task(F &amp;amp;&amp;amp;f, Args &amp;amp;&amp;amp;...args) -&amp;gt; std::future&amp;lt;typename std::result_of&amp;lt;F(Args...)&amp;gt;::type&amp;gt; { using return_type = typename std::result_of&amp;lt;F(Args...)&amp;gt;::type; auto ptask = std::make_shared&amp;lt;std::packaged_task&amp;lt;return_type()&amp;gt;&amp;gt;( std::bind(std::forward&amp;lt;F&amp;gt;(f), std::forward&amp;lt;Args&amp;gt;(args).</description>
    </item>
    <item>
      <title>Web Day10：加入线程池到服务器</title>
      <link>http://localhost:1313/posts/tech/web-day10.zh/</link>
      <pubDate>Sat, 18 Nov 2023 15:19:11 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/web-day10.zh/</guid>
      <description>前言 到 day9 的时候，一个单线程的服务器已经算写好了。Reactor 驱动大致成型。&#xA;服务器的启动流程大致如下，先创建 EventLoop 对象 loop（里面包含了 Epoll 对象），然后 Server 会利用 loop 实例化对象 server，Server 对象实例化时，Acceptor 类型的 acceptor_ 对象会被初始化, Acceptor 对象用于建立连接，会在 Server 的构造函数里回调函数 acceptor_-&amp;gt;new_conn_callback_ 会被注册为 server-&amp;gt;NewConn(Socket *clnt_sock) ，由 acceptor_-&amp;gt;AcceptConn() 来调用。而 Acceptor 的构造函数中 Channel 类的实例 accept_ch_ 会被初始化，而回调函数 acceptr_ch-&amp;gt;callback_ 会被注册为 acceptor_-&amp;gt;AcceptConn()，最终还是调用的 server-&amp;gt;NewConn(Socket *clnt_sock)。&#xA;Server::Server(EventLoop *loop) : loop_(loop), acceptor_(nullptr) { acceptor_ = new Acceptor(loop); std::function&amp;lt;void(Socket *)&amp;gt; callback = [this](auto &amp;amp;&amp;amp;PH1) { NewConn(std::forward&amp;lt;decltype(PH1)&amp;gt;(PH1)); }; acceptor_-&amp;gt;set_new_conn_callback(callback); } void Server::NewConn(Socket *sock) { auto *conn = new Connection(loop_, sock); // 这里应该是 clnt_sock std::function&amp;lt;void(Socket *)&amp;gt; callback = [this](auto &amp;amp;&amp;amp;PH1) { DeleteConn(std::forward&amp;lt;decltype(PH1)&amp;gt;(PH1)); }; conn-&amp;gt;set_delete_conn_callback(callback); connections_[sock-&amp;gt;getfd()] = conn; } void Acceptor::AcceptConn() { auto *clnt_addr = new InetAddress(); auto *clnt_sock = new Socket(sock_-&amp;gt;Accpet(clnt_addr)); printf(&amp;#34;new client fd %d!</description>
    </item>
    <item>
      <title>Web Day9：建立读写缓冲类</title>
      <link>http://localhost:1313/posts/tech/web-day9.zh/</link>
      <pubDate>Sat, 18 Nov 2023 14:53:43 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/web-day9.zh/</guid>
      <description>概述 本节只是额外添加了一个读写的缓冲区，意义不甚明了。暂定。</description>
    </item>
    <item>
      <title>Web Day8：抽象出 Connection 类</title>
      <link>http://localhost:1313/posts/tech/web-day8.zh/</link>
      <pubDate>Thu, 16 Nov 2023 15:25:27 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/web-day8.zh/</guid>
      <description>Acceptor 类 一言以蔽之，Acceptor 类负责接受连接，调用 AcceptConn，到这里，接受连接已经完全由 Acceptor 类来负责。Acceptconn 会调用被注册的回调函数 new_conn_callback_(clnt_sock)，实际上就是调用 Server::NewConn(clnt_sock)，该函数会将 {clnt_fd, conn} 的键值对添加到 Server 类的 map 中去。&#xA;此外，还会为 Connection 类注册删除 Connection 的回调函数；&#xA;void Acceptor::AcceptConn() { auto *clnt_addr = new InetAddress(); auto *clnt_sock = new Socket(sock_-&amp;gt;Accpet(clnt_addr)); printf(&amp;#34;new client fd %d! IP: %s Port: %d\n&amp;#34;, clnt_sock-&amp;gt;getfd(), inet_ntoa(clnt_addr-&amp;gt;get_addr().sin_addr), ntohs(clnt_addr-&amp;gt;get_addr().sin_port)); clnt_sock-&amp;gt;Setnonblocking(); new_conn_callback_(clnt_sock); delete clnt_addr; } void Server::NewConn(Socket *sock) { auto *conn = new Connection(loop_, sock); // 这里应该是 clnt_sock std::function&amp;lt;void(Socket *)&amp;gt; callback = [this](auto &amp;amp;&amp;amp;PH1) { DeleteConn(std::forward&amp;lt;decltype(PH1)&amp;gt;(PH1)); }; conn-&amp;gt;set_delete_conn_callback(callback); connections_[sock-&amp;gt;getfd()] = conn; Acceptor 的回调函数的注册过程发生在 Server 类的创建过程中。</description>
    </item>
    <item>
      <title>Web Day6：EventLoop 类与事件驱动</title>
      <link>http://localhost:1313/posts/tech/web-day6.zh/</link>
      <pubDate>Wed, 15 Nov 2023 20:09:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/web-day6.zh/</guid>
      <description>事件驱动 原先的代码中，不管是接受客户端连接还是处理客户端事件，都是围绕epoll来编程，可以说epoll是整个程序的核心，服务器做的事情就是监听epoll上的事件，然后对不同事件类型进行不同的处理。这种以事件为核心的模式又叫事件驱动，事实上几乎所有的现代服务器都是事件驱动的。和传统的请求驱动模型有很大不同，事件的捕获、通信、处理和持久保留是解决方案的核心结构。&#xA;将服务器改造成 Reactor 模式 我们将服务器抽象成一个 Server 类，类中有一个 main-reactor，main-reactor 的核心是一个 EventLoop，即不断循环，一旦有事件发生，我们就会通过 ep-&amp;gt;Poll 知晓，然后作出对应的处理。&#xA;Channel 的修改 day5 中，每个 channel 里面都含有一个 Epoll * 指针，表示它在哪个 epoll 实例中被关注，这里我们把 Epoll * 替换成了 EventLoop *，表示该 channel 处于哪个事件循环中，事实上 EventLoop 的关键成员就是 Epoll *。&#xA;初始化流程 首先创建 EventLoop 对象 loop，它会创建一个 Epoll 实例，核心就是 epfd，然后利用 loop 初始化 Server 对象，在这个过程中，会完成服务器的 serv_fd 的创建以及 bind，listen，同时将对应着 serv_fd 以及新建连接事件的 Channel 创建出来，将 Channel 的处理事件的回调函数设置为 NewConn；调用 serv_ch-&amp;gt;EnableReading 会将关注的事件类型设置为 EPOLLIN | EPOLLET 并调用 loop-&amp;gt;UpdateChannel(this) 最终调用 ep-&amp;gt;UpdateChannel(ch)，从而将 serv_ch 对应的文件描述符添加到 epoll 关注的文件描述符列表或者修改。</description>
    </item>
    <item>
      <title>Web Day 5 添加 Channel 类</title>
      <link>http://localhost:1313/posts/tech/web-day5.zh/</link>
      <pubDate>Wed, 15 Nov 2023 15:29:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/web-day5.zh/</guid>
      <description>Channel 类 Channel 类相当于将 ep-&amp;gt;addFd 这一步拆成了两步，第一步是 ch-&amp;gt;enablereading，它会调用 ep-&amp;gt;UpdateChannel(this)，this 就是调用 enablereading 的那个 ch。&#xA;如何理解 Channel 类？可以认为每一个 ch 的实例，都对应着一个关注的文件描述符 fd 和一个要关注的事件类型 events，当前其实只有两类 Channel，一个是对应的服务器的 fd，另一类对应的是 accept 客户端的连接之后得到的 fd，ch-&amp;gt;events 是 fd 所在的 Channel 实例需要关注的事件类型。&#xA;而 active_events 表示该 Channel 当前发生的事件类型，在 ep-&amp;gt;Poll() 中会被设置。&#xA;auto Epoll::Poll(int timeout) -&amp;gt; std::vector&amp;lt;Channel *&amp;gt; { std::vector&amp;lt;Channel *&amp;gt; active_channels; int nfds = epoll_wait(epfd, events, MAX_EVENTS, timeout); errif(nfds == -1, &amp;#34;epoll wait error\n&amp;#34;); active_channels.reserve(nfds); for (int i = 0; i &amp;lt; nfds; ++i) { Channel *ch = (Channel *)events[i].</description>
    </item>
    <item>
      <title>C&#43;&#43; 面经</title>
      <link>http://localhost:1313/posts/tech/cpp_interview.zh/</link>
      <pubDate>Tue, 07 Nov 2023 14:28:37 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/cpp_interview.zh/</guid>
      <description>1. 多态，虚函数 1. 什么是多态，如何实现多态(⭐⭐) 所谓多态，就是同一个函数名具有多种状态，或者说一个接口具有不同的行为；C++的多态分为编译时多态和运行时多态，编译时多态也称为为静态联编，通过重载和模板来实现，运行时多态称为动态联编，通过继承和虚函数来实现&#xA;2. 虚函数的实现机制(⭐⭐⭐) 虚函数是通过虚函数表来实现的，虚函数表包含了一个类(所有)的虚函数的地址，在有虚函数的类对象中，它内存空间的头部会有一个虚函数表指针(虚表指针)，用来管理虚函数表。当子类对象对父类虚函数进行重写的时候，虚函数表的相应虚函数地址会发生改变，改写成这个虚函数的地址，当我们用一个父类的指针来操作子类对象的时候，它可以指明实际所调用的函数&#xA;3. 虚函数调用是在编译时确定还是运行时确定的，如何确定调用哪个函数 当使用指针或引用调用虚函数的时候，是运行时确定，通过查找虚函数表中的函数地址确定&#xA;而使用普通变量调用虚函数的时候，是编译器确定的，此时没有多态&#xA;虚函数表是在编译阶段生成的，存放在只读数据段.rodata(和全局常量、字符串常量存放在一起)&#xA;4. 在(基类的)构造函数和析构函数中调用虚函数会怎么样(⭐⭐) 从语法上讲，调用没有问题，但是从效果上看，往往不能达到需要的目的（不能实现多态）；因为调用构造函数的时候，是先进行父类成分的构造，再进行子类的构造。在父类构造期间，子类的特有成分还没有被初始化，此时下降到调用子类的虚函数，使用这些尚未初始化的数据一定会出错；同理，调用析构函数的时候，先对子类的成分进行析构，当进入父类的析构函数的时候，子类的特有成分已经销毁，此时是无法再调用虚函数实现多态的&#xA;5. C 语言可以实现虚函数机制吗，如何实现 需要做的工作：手动构造父子关系、创建虚函数表、设置虚表指针并指向虚函数表、填充虚函数表；当虚函数重写的时候还需要手动修改函数指针等等&#xA;6. 重载、重写和隐藏的区别(⭐⭐) 重载指的是同一个名字的函数，具有不同的参数列表（参数类型、个数），或不同的返回类型，根据参数列表和返回类型决定调用哪一个函数；&#xA;重写（覆盖）指的是，派生类中的函数重写了基类中的虚函数，重写的基类的中函数必须被声明为virtual，并且返回值，参数列表和基类中的函数一致(除非返回类型是基类/派生类的指针/引用)；&#xA;隐藏是指，派生类中的同名函数把基类中的同名函数隐藏了，包括所有的重载版本，不论是不是虚函数都会隐藏&#xA;7. 模板类可以有虚函数吗，模板函数可以是虚函数吗 模板类可以使用虚函数。但使用模板类定义不同的类型则是两个完全不同的类，即使两个泛型参数是父类和子类关系，两个泛型变量也没有任何父子关系&#xA;模板函数不能是虚函数。编译器都期望在处理类的定义的时候就能确定这个类的虚函数表的大小，如果允许有类的虚成员模板函数，那么就必须要求编译器提前知道程序中所有对该类的虚成员模板函数有多少个版本，才能分配虚函数表的大小，而这是不可行的&#xA;8. 内联函数可以是虚函数吗，静态函数可以是虚函数吗(⭐⭐) 内联函数表示在编译阶段进⾏函数体的替换操作(内联函数实际上不是函数)，⽽虚函数意味着在运⾏期间进⾏类型确定，要经过函数调用的过程，所以内联函数不能是虚函数(将函数同时声明inline virtual编译器会直接忽略inline) 静态函数不属于类对象而属于类，静态成员函数没有 this 指针，所以无法找到虚表，也就无法实现虚函数重写的功能，所以不能是虚函数 9. 多个基类的同名虚函数覆写问题(⭐) 假设一个子类继承两个基类，这两个基类都有一个虚函数func，那么直接用子类变量调用func就会出现歧义，因为不知道是哪一个func，其实就是不知道使用哪个虚表的信息&#xA;如果用这两个基类的指针指向这个子类变量，那么用这两个基类指针就能成功调用这个虚函数了，因为两个基类指针确定了是使用自己类的虚表&#xA;若子类又覆写了这个同名的虚函数，此时会将两个虚表中的该函数全部覆写，那直接用子类变量也能直接调用func，此时没有歧义，因为两个虚函数实现是一样的了&#xA;2. 内存与继承 1. C++ 中类对象的内存模型(布局)是怎么样的(⭐⭐⭐) 如果是有虚函数的话，虚函数表的指针始终存放在内存空间的头部&#xA;除了虚函数之外，内存空间会按照类的继承顺序(父类到子类)和字段的声明顺序布局&#xA;如果有多继承，每个包含虚函数的父类都会有自己的虚函数表，并且按照继承顺序布局(虚表指针 + 字段）；如果子类重写父类虚函数，都会在每一个相应的虚函数表中更新相应地址；如果子类有自己的新定义的虚函数或者非虚成员函数，也会加到第一个虚函数表的后面&#xA;如果有菱形继承，并采用了虚继承，则内存空间排列顺序为：各个父类(包含虚表)、子类、公共基类(虚基类，包含虚表)，并且各个父类不再拷贝虚基类中的数据成员&#xA;2. 菱形继承存在什么问题，如何解决 会存在二义性的问题，因为两个父类会对公共基类的数据和方法产生一份拷贝，因此对于子类来说读写一个公共基类的数据或调用一个方法时，不知道是哪一个父类的数据和方法，也会导致编译错误。可以采用虚继承的方法解决这个问题，这样就只会创造一份公共基类的实例，不会造成二义性&#xA;在钻石继承时，使用最高层的公共基类指向最底层的派生类，就会报错，因为编译器不知道是指向哪个派生类的基类区域&#xA;3. C++ 是如何做内存管理的（有哪些内存区域）(⭐⭐⭐) 堆，使用malloc、free动态分配和释放空间，能分配较大的内存 栈，为函数的局部变量分配内存，能分配较小的内存 全局/静态存储区，用于存储全局变量和静态变量 常量存储区，专门用来存放常量 自由存储区：通过new和delete分配和释放空间的内存，具体实现可能是堆或者内存池 4. C++ 内存有哪些段 代码段.text存放函数代码 .bss段存放未初始化的全局变量，未初始化的全局静态变量和局部静态变量 数据段.data存放已经初始化的全局变量，已初始化的全局静态变量和局部静态变量 只读数据段.</description>
    </item>
    <item>
      <title>差分数组</title>
      <link>http://localhost:1313/posts/tech/difference_array.zh/</link>
      <pubDate>Fri, 06 Oct 2023 17:50:12 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/difference_array.zh/</guid>
      <description>介绍 考虑原数组为 $[1, 3, 3, 5, 8]$，我们对相邻元素做差，用 $a_i - a_{i - 1}$，可以得到一个差分数组 $[1, 2, 0, 2, 3]$ $diff$，我们认为 $a_{-1}$ 为 $0$，因此&#xA;$$diff[i] = \begin{cases} a[0] &amp;amp; i = 0 \newline a[i] - a[i - 1] &amp;amp; i &amp;gt; 0\end{cases}$$&#xA;性质 差分数组往往和前缀和数组放在一块讨论，事实上，差分数组的前缀和即可还原出原数组。即：&#xA;$$ a[k] = \sum\limits_{i = 0}^k diff[i]$$&#xA;差分数组还有一个非常重要的性质，那就是它可以将区间修改（将区间中的每个元素都加一个值或者减一个值）变成单点修改。&#xA;例如，加入我们要将区间 $[i, j]$ 中的每个元素都加 $c$，那么我们只需要将 $diff[i]$ 加 $c$，并将 $diff[j + 1]$ 减去 $c$ 即可，由这个差分数组取前缀和还原出来的原数组，就是我们修改后的原数组。</description>
    </item>
    <item>
      <title>Xv6 Lab11: Mmap</title>
      <link>http://localhost:1313/posts/tech/xv6-lab11.zh/</link>
      <pubDate>Thu, 03 Aug 2023 13:53:24 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/xv6-lab11.zh/</guid>
      <description>思路与实现 添加系统调用就不多说了。&#xA;整体流程应该是这样的，lab 的提示中，要求我们定义一个 vma 结构体，vma 的定义如下；然后 lab 的提示要求我们声明一个大小为 $16$ 的 vma 数组，并按需要从该数组分配，问题来了，数组在哪里声明呢？考虑到每个进程都有自己的虚拟地址空间，因此，每个进程都有自己的 virtual memory areas，要分配 vma 的时候，应该从每个进程自己的 vma 数组进行分配，于是，我们可以考虑为 struct proc 添加 struct vma areas[NVMA] 字段。&#xA;struct vma { int fd; int rw_flag; uint64 start; uint64 cur; uint len; int state; int flags; }; struct proc { // 已有的省略不写 struct vma areas[NVMA]; }; 在 vma 的定义中，start 表示起始地址，$[start, cur)$ 这一段虚拟地址（左闭右开）是已经绑定了 pp 的，pp 的数据与 file 绑定。&#xA;那么我们如何实现 sys_mmap 呢？这里可以参照 sbrk，递增 p-&amp;gt;sz，然后仿照 allocproc，寻找状态为 UNUSED 的 vma，分配给本次 sys_mmap。注意如果文件本身是 read_only，并且以 MAP_SHARED 模式进行 map，那么 flags 不能为 PROT_WRITE，write only 的情况同理（即文件不可读）。</description>
    </item>
    <item>
      <title>Xv6 Lab10: file system</title>
      <link>http://localhost:1313/posts/tech/xv6-lab10.zh/</link>
      <pubDate>Tue, 01 Aug 2023 20:19:47 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/xv6-lab10.zh/</guid>
      <description>Large files 这个作业需要我们将 xv6 的最大文件大小从 12 + 256 Bytes 修改为 11 + 256 + 256 * 256 Bytes。&#xA;为了达成这个目标，我们需要使用二级索引块，对 inode 的 addrs 字段，首先将 NDIRECT 从 $12$ 修改为 $11$，即前 $11$ 个 block 是 direct block，addrs[NDIRECT] 对应的块是一个一级索引块，这个块中的每个元素（共 BSIZE / sizeof(uint) 个元素）都是一个数据块的编号；而 addrs[NDIRECT + 1] 是一个二级索引块，这个块中的每个元素都是一级索引块的编号，由编号找到一级索引块，然后再由以及索引块找到数据块。&#xA;这个作业的主要任务就是修改 bmap 和 itrunc 两个函数。&#xA;先修改 fs.h 中的 NDIRECT 的相关定义：&#xA;#define FSMAGIC 0x10203040 #define NDIRECT 11 #define NINDIRECT (BSIZE / sizeof(uint)) #define NDINDIRECT (NINDIRECT * NINDIRECT) #define MAXFILE (NDIRECT + NINDIRECT + NDINDIRECT) struct dinode { short type; // File type short major; // Major device number (T_DEVICE only) short minor; // Minor device number (T_DEVICE only) short nlink; // Number of links to inode in file system uint size; // Size of file (bytes) uint addrs[NDIRECT + 2]; // Data block addresses }; 注意 file.</description>
    </item>
    <item>
      <title>Xv6 Lab9: Locks</title>
      <link>http://localhost:1313/posts/tech/xv6-lab9.zh/</link>
      <pubDate>Sat, 29 Jul 2023 14:28:58 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/xv6-lab9.zh/</guid>
      <description>Memory allocator 这一题很简单，主要任务，就是为每个 cpu 维护一个空闲物理内存的链表 freelist，xv6 默认使用的结构体 kmem，其中包含一个 freelist 供所有的 cpu 使用。我们要做的，就是把 freelist 修改成 freelist 的数组，即 struct run *freelist[NCPU]，其中 NCPU 是定义于 kernel/params.h 的宏，对应 cpu 的个数。 kmem 中的 spinlock 是用来保护 freelist 的，既然 freelist 变成了数组，那么也需要有 NCPU 个 spinlock。因此，修改 kmem 为如下结构体：&#xA;struct { struct spinlock lock[NCPU]; struct run *freelist[NCPU]; // for each cpu, allocate a freelist } kmem; 接着，我们需要修改 kinit，让它初始化每个 spinlock。&#xA;void kinit() { char lockname[6] = {&amp;#39;k&amp;#39;, &amp;#39;m&amp;#39;, &amp;#39;e&amp;#39;, &amp;#39;m&amp;#39;, &amp;#39;0&amp;#39;, 0}; for (int i = 0; i &amp;lt; NCPU; ++i) { lockname[4] = &amp;#39;0&amp;#39; + i; initlock(kmem.</description>
    </item>
    <item>
      <title>虚拟内存</title>
      <link>http://localhost:1313/posts/tech/virtual_memory.zh/</link>
      <pubDate>Fri, 28 Jul 2023 19:55:47 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/virtual_memory.zh/</guid>
      <description>虚拟地址空间与物理地址空间 地址空间（address space）是一个非负整数地址的有序集合：&#xA;$$\lbrace 0, 1, 2, \cdots\rbrace$$&#xA;如果地址空间中的整数是连续的，那么我们说它是个线性地址空间（linear address space），为了简化讨论，我们总是假设我们使用的是线性地址空间。&#xA;地址空间的大小由表示最大地址所需的位数来决定，例如 $N - 1= 2^n - 1$，因此最大地址需要 $n$ 位数来表示，于是一个包含 $N = 2^n$ 个地址的地址空间就叫一个 $n$ 位地址空间。&#xA;虚拟地址空间 在一个带虚拟内存的系统中，CPU 由 $N=2^n$ 的地址空间中生成虚拟地址，这个虚拟地址的有序集合称为虚拟地址空间（virtual address space）：&#xA;$$ \lbrace 0, 1, 2, \cdots N - 1\rbrace$$&#xA;这个地址空间是 $n$ 位的。&#xA;物理地址空间 一个系统还有一个物理地址空间（physical address space），对应于系统中物理内存的 $M$ 个字节：&#xA;$$\lbrace0,1,2,\cdots,M-1\rbrace$$&#xA;$M$ 并不要求是 $2$ 的幂，例如可能是 $12GB$，但是为了简化讨论，我们假设 $M=2^m$，即地址空间是 $m$ 位的。&#xA;物理内存作为虚拟内存的缓存 概念上而言，虚拟内存被组织为一个存放在磁盘上的由 $N=2^n$ 个连续字节大小的单元组成的数组，每个字节都有一个唯一的虚拟地址，作为到数组的索引；对应的，计算机的主存（main memory，后面简称内存）被组织成一个由 $M=2^m$ 个连续的字节大小的单元组成的数组，每字节都有一个唯一的物理地址。&#xA;VM（Virtual Memory）系统通过将虚拟内存分割为称为虚拟页（Virtual Page，VP）的大小固定的块来处理这个问题，每个虚拟页的大小为 $P=2^p$ 字节。相应的，物理内存被分割为物理页（Physical Page，PP）来处理，大小也为 P 字节。这里的物理页就像是 SRAM cache 中的 block。</description>
    </item>
    <item>
      <title>MIT 6.S081 File system performance and fast crash recovery</title>
      <link>http://localhost:1313/posts/tech/mit6.s081-lec16.zh/</link>
      <pubDate>Thu, 27 Jul 2023 16:34:51 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/mit6.s081-lec16.zh/</guid>
      <description>引入 当我们针对文件系统讨论 logging 或者 journal 时，其实是在讨论同一件事，二者是同义词。&#xA;这一部分主要是讨论 Linux 的 ext3 文件系统，它相比 ext2，可以就说就是加了一层 logging，其他基本没有改变。我们要关注 ext3 与 xv6 的文件系统的不同之处，重点放在 ext3 是如何在保证 logging 的同时尽可能提升性能的。&#xA;ext3 file system log format ext3 数据结构与 xv6 相似，在内存中存在 block cache，它们是 write-back 的（即改动不会马上写回到磁盘）。&#xA;logging 系统有两个非常重要的准则：&#xA;write-adead rule：必须现在 log 中记录好所有这些写操作，才能将这些写操作应用到磁盘； freeing rule：即我们不能覆盖或者重用 log。 ext3 还维护了一些 transaction 的信息，transaction_t 中包含：&#xA;一个序列号； 一系列该 transaction 修改的 block 的编号，这些 block 编号指向 cache 中的 blcok； 一系列的 handle，handle 对应属于transaction 的系统调用，它们会读写 cache 中的 block； ext3 的磁盘组织与 xv6 类似，存在一个文件系统树，包含 inode、目录、file 等，存在 bimtap lock 来标识每个 data block 是被分配还是空闲的，在磁盘的一个指定区域保存 log。</description>
    </item>
    <item>
      <title>Mit6.s081 Lec15: xv6 的 logging system</title>
      <link>http://localhost:1313/posts/tech/mit6.s081-lec15.zh/</link>
      <pubDate>Tue, 25 Jul 2023 16:48:39 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/mit6.s081-lec15.zh/</guid>
      <description>Logging layer file system 设计的一大重要问题就是 crash recovery。这是因为文件系统操作往往涉及向磁盘多次写入，而几次写入之后的 crash 可能导致磁盘上的文件系统处于一个不一致的状态。&#xA;For example, suppose a crash occurs during file truncation (setting the length of a file to zero and freeing its content blocks). Depending on the order of the disk writes, the crash may either leave an inode with a reference to a content block that is marked free, or it may leave an allocated but unreferenced content block.&#xA;前者当系统重启之后,可能导致一个磁盘 block 被两个文件所对应，这是一个很严重的问题。</description>
    </item>
    <item>
      <title>MIT 6.S081 Lec14: File system</title>
      <link>http://localhost:1313/posts/tech/mit6.s081-lec14.zh/</link>
      <pubDate>Sat, 22 Jul 2023 19:51:29 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/mit6.s081-lec14.zh/</guid>
      <description>Overview 文件系统的设计目标就是组织和存储数据，文件系统一个比较重要功能是持久化，即重启之后，数据不会丢失。xv6 通过把数据存储在 virtio disk 上来实现持久化。&#xA;文件系统设计的几大挑战：&#xA;The file system needs on-disk data structures to represent the tree of named directories and files, to record the identities of the blocks that hold each file’s content, and to record which areas of the disk are free. 由于文件系统需要实现持久化，因此必须要实现 crash recovery，即如果发生意外的 crash（例如断电），文件系统在计算机重启之后要能依旧正常工作； 可能有多个进程同时操作文件系统； 由于访问磁盘比访问内存要慢得多得多，因此文件系统需要能支持将部分 popluar 的 blocks 缓存在内存中； xv6 的文件系统可以说组织为七层，如下图所示：&#xA;disk layer 负责读写 virtio hard drive 上的 blocks，buffer cache layer 是 blocks 的 cache，并且保证同一时间，只有一个内核进程可以修改存储在特定块上的数据；logging layer 将对几个特定 block 的更新打包为一次 transaction（就是数据库常说的事务？），从而确保这些 blocks 都是被原子化地更新，即要么一次都更新，要么一次都不更新；inode layer 则是用来表示单独的文件，每个文件都是以具有不重复的 index 的 inode 和保存了这个文件的数据的一些 blocks 来表示；而在 directory layer，每个 directory 都是一种特殊的 inode，包含一系列 direcotry entry，directory entry 则是包含了文件名和 index（对应 indode layer 所说的 index）；pathname layer 提供了层级化的路径名，利用递归查找来解析它们；</description>
    </item>
    <item>
      <title>Xv6 Lab7: Multithreading</title>
      <link>http://localhost:1313/posts/tech/xv6-lab7.zh/</link>
      <pubDate>Sat, 22 Jul 2023 11:30:01 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/xv6-lab7.zh/</guid>
      <description>Uthread: switching between threads 这个题还是对的起它 moderate 的难度了，如果认真看了 book-riscv-rev2.pdf 的 Scheduling 章节，以及看了这个 课程翻译，那么这题可以很快做出来，个人觉得 pdf 讲得更加清楚一些。&#xA;这个题甚至帮你把需要添加代码的地方都标注出来了，参照题目说明，主要有三步：&#xA;修改 thread_create 来保证当 thread_schedule 第一次运行 thread_create 创建出来的线程时，该线程就会在自己的 stack 上执行传递给 thread_create 的函数，这里我们可以参照 allocproc 的实现，在 thread_create 标记出来的要我们添加代码的地方添加如下三行： memset(&amp;amp;t-&amp;gt;context, 0, sizeof(t-&amp;gt;context)); t-&amp;gt;context.ra = (uint64)func; t-&amp;gt;context.sp = (uint64)t-&amp;gt;stack + STACK_SIZE; 保证 thread_switch 会切换并保存寄存器，这里参照 scheduler 的实现即可，在注释标记的地方添加以下语句，并且在 uthread_switch.S 中实现 thread_switch 函数（照抄 swtch 即可）： thread_switch((uint64)&amp;amp;t-&amp;gt;context, (uint64)&amp;amp;current_thread-&amp;gt;context); thread_switch: /* YOUR CODE HERE */ sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret /* return to ra */ 修改 strcut thread 来存储 thread_switch 时需要保存的寄存器，还是参照 struct proc 即可： struct t_context { uint64 ra; uint64 sp; // callee saved uint64 s0; uint64 s1; uint64 s2; uint64 s3; uint64 s4; uint64 s5; uint64 s6; uint64 s7; uint64 s8; uint64 s9; uint64 s10; uint64 s11; }; struct thread { char stack[STACK_SIZE]; /* the thread&amp;#39;s stack */ int state; /* FREE, RUNNING, RUNNABLE */ struct t_context context; }; 这样修改之后就能通过 uthread 了。</description>
    </item>
    <item>
      <title>MIT 6.S081 Sleep &amp; Wake up</title>
      <link>http://localhost:1313/posts/tech/mit6.s081-lec13.zh/</link>
      <pubDate>Thu, 20 Jul 2023 17:40:26 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/mit6.s081-lec13.zh/</guid>
      <description>Sleep and wakeup Sleep 允许一个内核线程等待某个特定事件的发生，另一个线程可以调用 wakeup 来表示这个正在等待时间发生的线程应该恢复了。&#xA;Sleep and wakeup are often called sequence cooridination or conditional synchronization mechanisms.&#xA;xv6 中利用 sleep 和 wakeup 实现了一种 high-level 的同步机制，被称为信号量（semaphore），用于协调生产者和消费者（xv6 中并未使用信号量）。&#xA;A semaphore maintains a count and provides two operations. The “V” operation (for the producer) increments the count. The “P” operation (for the consumer) waits until the count is non-zero, and then decrements it and returns.&#xA;struct semaphore { struct spinlock lock; int count; }; void V(struct semaphore *s) { acquire(&amp;amp;s-&amp;gt;lock); s-&amp;gt;count += 1; // wakeup(s); release(&amp;amp;s-&amp;gt;lock); } void P(struct *s) { while (s-&amp;gt;count == 0) //sleep(s); ; acquire(&amp;amp;s-&amp;gt;lock); s-&amp;gt;count -= 1; release(&amp;amp;s-&amp;gt;count); } 上述代码给出了一个非常简单但是性能不优秀的 “生产者-消费者” 模型实现，如果生产者很少工作，那么消费者会花费大量时间在 while 循环中。为了避免这一点，消费者应该要有办法主动让出 cpu，并且只在 V 递增 s-&amp;gt;count 之后才恢复执行。</description>
    </item>
    <item>
      <title>MIT 6.S081 Thread switching</title>
      <link>http://localhost:1313/posts/tech/mit6.s081-lec11.zh/</link>
      <pubDate>Wed, 19 Jul 2023 10:46:24 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/mit6.s081-lec11.zh/</guid>
      <description>Multiplexing xv6 通过将 cpu 从一个进程切换到另一个进程来实现 multiplex（多路复用），进程的切换会在两种情形下发生：&#xA;xv6 的 sleep 与 wakeup 机制在进程等待 IO 完成或者等待子进程退出又或者在 sleep 系统调用中等待的时候切换进程。 xv6 会周期性地强制切换进程，从而应对那些长时间切换而未 sleep 的进程。 这个 multiplex 机制会让进程产生一种自己完全拥有 cpu 的错觉，就像 xv6 用虚拟内存和 page table 机制让进程觉得自己拥有完整的内存空间一样。&#xA;xv6 使用硬件定时器中断来保证 context switch（上下文切换）。&#xA;Code: Context switching 用户进程之间的切换步骤如下图所示：&#xA;用户进程之间的切换其实会经过两次 context switch，以上图为例，第一次是从 shell 用户进程的 kernel thread 切换到 cpu 的 scheduler thread；第二次从 cpu 的 scheduler thread 切换到新用户进程（例如 cat）的 kernel thread。&#xA;在 xv6 中，我们可以认为每个用户进程，包含一个内核线程与一个用户线程，然后每个 cpu 包含一个 scheduler thread，schedular thread 工作在内核中，有只属于它的 kernel stack。&#xA;swtch 执行为内核线程切换的保存和恢复工作。swtch 的主要工作就是保存和恢复 riscv 的寄存器，又被称为上下文。</description>
    </item>
    <item>
      <title>MIT 6.S081 Multiprocessors and locking</title>
      <link>http://localhost:1313/posts/tech/mit6.s081-lec10.zh/</link>
      <pubDate>Tue, 18 Jul 2023 13:54:16 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/mit6.s081-lec10.zh/</guid>
      <description>why lock 防止多核并行运行下的 race condition 导致的错误。&#xA;内核中的数据是典型的 concurrently-accessed 的数据。&#xA;race condition and how the lock avoid it A race condition is a situation in which a memory location is accessed concurrently, and at least one access is a write.&#xA;Locks ensure mutual exclusion. 锁的持有与释放之间的语句会被原子化，在 xv6 中，就是 acquire 和 release 之间的多条语句，只能被一个进程（CPU）全部执行完了之后，才可能被其他的进程（CPU）执行，这样就避免了 race condition。&#xA;acquire 和 release 之间的多条指令通常被称为 critical section。&#xA;lock 在某种意义上是在维护 critical section 中一些数据的不变量（some collection of invariants），这个不变量在 critical section 中可能会被暂时破坏，但是当 critical section 的最开始，以及结束的时候，这个 invariants 一定成立！ 例如 kfree 中的 lock，就是在维护 kmem.</description>
    </item>
    <item>
      <title>无向图形式组织的树</title>
      <link>http://localhost:1313/posts/tech/undirected-graph-tree.zh/</link>
      <pubDate>Tue, 18 Jul 2023 09:30:57 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/undirected-graph-tree.zh/</guid>
      <description>引入 如 数组形式组织的树 中所说，树一般以链表结点的形式组织，定义如下：&#xA;struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x): val(x), left(nullptr), right(nullptr) {} }; 也可能以数组的形式组织，即使用 $parent$ 数组，$y = parent[x]$ 说明 $y$ 是 $x$ 的父结点，根结点的父结点为 $-1$，表示父结点不存在。&#xA;还可以使用无向图的形式来表示，例如 leetcode 的 834. 树中距离之和。&#xA;昨天做这个题的时候，整体思路挺好想的，但就是有个地方被困住了，那就是，在树的无向图的表示情况下，如何统计以当前结点为根结点的子树的数量？（没办法转化成有向图！）&#xA;统计以当前结点为根结点的子树的结点数 统计方法还是深度优先搜索（dfs），只不过，相比一般的深度优先搜索，我们需要传入一个额外的参数，即上一次搜索的父结点，如下图所示：&#xA;相应的 dfs 代码为&#xA;for (int child : tree[pa]) { if (child == ancestor) { continue; } // 对子结点进行 dfs ... } 这样就确定出了一个遍历方向，因此，整体思路就是，我们可以任意选择一个结点作为 dfs 的起点（这里就选择 $0$ 号结点），依次进行 dfs，利用递归的方法，统计以当前结点为根结点的子树的结点数。&#xA;因此，834. 树中距离之和 的完整解题代码如下：&#xA;class Solution { public: int count(vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; &amp;amp;tree, vector&amp;lt;int&amp;gt; &amp;amp;dis, vector&amp;lt;int&amp;gt; &amp;amp;cnt, int pa, int grandpa) { int res = 1; for (int child : tree[pa]) { if (child == grandpa) { // 防止重复遍历，保证 dfs 遍历时的单向性 continue; } dis[child] = dis[pa] + 1; res += count(tree, dis, cnt, child, pa); } cnt[pa] = res; return res; } vector&amp;lt;int&amp;gt; sumOfDistancesInTree(int n, vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; &amp;amp;edges) { vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; tree(n); for (auto &amp;amp;vec : edges) { tree[vec[0]].</description>
    </item>
    <item>
      <title>MIT 6.S081 Page faults</title>
      <link>http://localhost:1313/posts/tech/mit6.s081-lec08.zh/</link>
      <pubDate>Mon, 17 Jul 2023 16:27:16 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/mit6.s081-lec08.zh/</guid>
      <description>概述 这一章主要聚焦于，我们利用 virtural memory 和 page fault 这两个机制，能够实现一些什么样的有意思的优化。&#xA;虚拟内存的有两大优势：&#xA;Isolation，保证每个进程都有它自己的虚拟地址空间，写自己的虚拟地址处的数据不会破坏其他进程的数据； Levle of indirection，提供了一层抽象（这里不是很好理解），可以理解为提供了一层从虚拟地址到物理地址的映射关系，利用这个映射关系，我们可以实现很多有意思的优化。 利用 page fault，我们可以更新 page table，即更改虚拟地址和物理地址之间的映射关系（在之前的 xv6 中，可以说 va 和 pa 的映射关系，在进程启动之后，到进程结束之前，都是固定的）。&#xA;对于 page fault，也可以说是一种 trap，之前提到的 system call 是发生了系统调用之后的 trap，因此 trap 完成之后，我们会返回到产生系统调用的指令的下一条指令继续执行；而 page fault 则是异常（exception）导致的 trap，trap 结束之后，我们会返回导致 page fault 的指令，重新执行这一条指令；&#xA;正如 system call 导致的 trap 中，我们需要实现真正执行 systemcall 的函数；而 page fault 导致的 trap 中，我们也需要处理这一异常（一般是在 trap.c 的 usertrap 函数中）。&#xA;对于处理 page fautl 的思路，其实可以参照 system call，我们通过读取 scause 寄存器的值来判断导致 trap 的原因，如果是 $13$ 或者 $15$，则说明是 page fault。</description>
    </item>
    <item>
      <title>Xv6 Lab6: Copy-on-Write Fork for xv6</title>
      <link>http://localhost:1313/posts/tech/xv6-lab6.zh/</link>
      <pubDate>Mon, 17 Jul 2023 13:42:27 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/xv6-lab6.zh/</guid>
      <description>思路 经过 lab5: lazy page allocation 之后，对 xv6 的 page fault 的处理，算是有所了解了。&#xA;今天这个 COW 实验，在 2020 年的课程视频中有对思路的讲解，可以先看看 课程翻译，厘清一下思路。&#xA;整体思路其实也不难，默认情况下，fork 会调用 uvmcopy，将父进程的 PP（物理页）复制一份，将这个 PP 的副本映射到子进程的 pagetable 的 VP（虚拟页）（子进程和父进程具有相同的虚拟地址，不同的 pagetable，不同的 PP，但是相同虚拟地址对应的 PP 的内容是一样的）。&#xA;我们这里讨论 vaddr、paddr 都是基于地址已经是 PGSIZE 对齐的情况来讨论的。&#xA;我们要做的修改就是，不再复制这个 PP，而是将 PP 的 paddr 同时映射到父进程的 vaddr 以及子进程的 vaddr。&#xA;在未修改 uvmcopy 之前，修改父进程的 vaddr 处的内容并不会影响子进程的 vaddr 处的内容，因为两个 vaddr 对应的是不同的 PP，只是 PP 的内容相同而已（在 pp 是 clean 的情况下）。&#xA;而修改了 uvmcopy 之后，写入父进程的 vaddr 会影响子进程的 vaddr 处的内容，这是我们不希望看到的，因此我们将这个 PP 对应的父进程的 pte 和子进程的 pte 的 PTE_W 位都清零，即标记为不可写，这样，当我们试图往这个 PP 中写入内容的时候，就会出现 page fault。</description>
    </item>
    <item>
      <title>Xv6 Lab5: lazy page allocation</title>
      <link>http://localhost:1313/posts/tech/xv6-lab5.zh/</link>
      <pubDate>Sat, 15 Jul 2023 17:18:30 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/xv6-lab5.zh/</guid>
      <description>前言 这个实验只有 2020 年的才有，2021 年的课程中是没有的，但是感觉这个实验还是挺有意义的，因此用 docker 创建了一个 debian 12 的容器，在容器中搭建了 2020 的实验环境，实验环境的搭建过程可以参照 MIT 6.s081 实验环境搭建。&#xA;Eliminate allocation from sbrk() 这个算是最简单的：&#xA;// kernel/sysproc.c uint64 sys_sbrk(void) { int addr; int n; if (argint(0, &amp;amp;n) &amp;lt; 0) { return -1; } addr = myproc-&amp;gt;sz; myproc()-&amp;gt;sz += n; // 添加的部分，修改 p-&amp;gt;sz，然后注释掉下面这三行 // if (growproc(n) &amp;lt; 0) { // return -1; // } return addr; } Lazy allocation 在去掉了 sys_sbrk 的 growproc 部分之后，由于只是单纯增加了 p-&amp;gt;sz，而没有给对应的虚拟地址分配物理页，因此，在执行 echo hi 时，会访问到 heap 中的未分配物理页的虚拟地址，于是出现 page fault，默认的 Xv6 的代码中并没有给出对 page fault 的处理，而是会直接杀死进程，因此无法正常执行完 echo hi。</description>
    </item>
    <item>
      <title>Xv6 Lab4: Traps</title>
      <link>http://localhost:1313/posts/tech/xv6-lab4.zh/</link>
      <pubDate>Thu, 13 Jul 2023 12:51:50 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/xv6-lab4.zh/</guid>
      <description>RISC-V assembly Which registers contain arguments to functions? For example, which register holds 13 in main&amp;rsquo;s call to printf?&#xA;a2 寄存器，函数调用时，参数从左到右会依次保存在 a0, a1, a2, a3 寄存器，似乎是一直到寄存器 a7 的。 Where is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)&#xA;这里的调用都被内联了 At what address is the function printf located?&#xA;auipc（Add Upper Immediate PC）指令是将一个立即数左移 $12$ 位加上当前指令的地址（pc）中，得到一个绝对地址。&#xA;例如 auipc a0, 0x0 就是将 $\text{0x0}$ 左移 $12$ 位加上当前指令的地址 (pc) 中（pc 的值我们一般认为是在指令执行完成时才发生递增，从而指向下一条指令，使得处理器能够按顺序顺利执行指令序列），因此，执行 auipc a0, 0x0 时，加的就是当前指令的地址，即 $\text{0x28}$。</description>
    </item>
    <item>
      <title>MIT 6.S081 Isolation &amp; System call entry/exit</title>
      <link>http://localhost:1313/posts/tech/mit6.s081-lec06.zh/</link>
      <pubDate>Sat, 08 Jul 2023 15:32:43 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/mit6.s081-lec06.zh/</guid>
      <description>Trap 机制 程序运行往往需要完成用户空间和内核空间的切换，每当：&#xA;程序执行系统调用（system call）； 程序出现了 page fault 等错误； 一个设备触发了中断； 都会发生这样的切换。&#xA;这里用户空间切换到内核空间通常被称为 trap，因此有时候我们会说程序“陷入”到内核态。trap 机制需要尽可能的简单。&#xA;trap 的工作，可以说是让硬件从适合运行用户程序的状态，切换到适合运行内核代码的状态。&#xA;这里说的状态中，我们最关心的状态可能是 $32$ 个用户寄存器，我们尤其需要关注以下硬件寄存器的内容：&#xA;堆栈寄存器（stack register，又称 stack pointer）； 程序计数器（Program Counter Register）； 表明当前 mode 的标志位的寄存器，表明当前是 supervisor mode 还是 user mode； 控制 CPU 工作方式的寄存器，例如 SATP（Supervisor Address Translation and Protection）寄存器，它包含了指向 page table 的物理内存地址； STVEC（Supervisor Trap Vector Base Address Register）寄存器，它指向了内核中处理 trap 的指令的起始地址； SEPC（Supervisor Exception Program Counter）寄存器，在 trap 的过程中保存程序计数器的值； sscratch（Supervisor Scratch Register）寄存器； 在 trap 的最开始，CPU 所有的状态肯定还是在运行用户代码而不是内核代码，在 trap 处理的过程中，我们会逐渐更改状态，或者对状态做一些操作，我们可以设想一下我们需要做哪些操作：&#xA;保存 $32$ 个用户寄存器的状态，例如，当响应中断完成后，我们会希望能恢复用户程序的执行，而这些寄存器需要被内核代码所使用，因此，在 trap 之前，我们需要保存这 $32$ 个用户寄存器的内容； 保存 PC 的内容，原因类似于保存 $32$ 个用户寄存器； 将 mode 修改为 supervisor mode； 运行内核代码前，将 SATP 由指向 user page table 修改为指向 kernel page table； trap 机制不会依赖于 $32$ 个用户寄存器；</description>
    </item>
    <item>
      <title>MIT 6.S081 页表</title>
      <link>http://localhost:1313/posts/tech/mit6.s081-page-table.zh/</link>
      <pubDate>Mon, 03 Jul 2023 09:19:09 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/mit6.s081-page-table.zh/</guid>
      <description>Paging hardware 总的来说，Xv6 的虚拟内存到物理内存的映射方式与 x64 是一致的，都是使用页表来进行映射。区别在于，Xv6 只使用了三级页表，而 x64 则是使用四级页表，另外，二者的页表层级的命名也有区别，对 Xv6 来说，最高级的页表是 L3（其地址存放于寄存器 satp 中）。&#xA;每个 page table 含有 512 个 page table entry，而每个 page table entry 的大小是 8KB，因此一个 page table 占据的大小正好是 4KB，即一个 VP 的大小！&#xA;标志位可以说是顾名思义，除了这个 dirty？（留待之后处理）&#xA;Kernel address space Xv6 中，每个进程都有属于自己的地址空间，以及一个全局唯一的描述内核地址空间的 page table，（kernel page table）。&#xA;内核内存布局：&#xA;QEMU 模拟了一台带 RAM（物理内存）的电脑，该 RAM 的起始地址是 $\text{0x80000000}$ ,结束地址至少是 $\text{0x86400000}$（该地址在 Xv6 中被定义为 PHYSTOP），这里的地址说的都是物理地址。&#xA;QEMU 会将设备接口以内存映射的控制寄存器暴露给系统软件，这些寄存器地址映射的内存都是在 $\text{0x80000000}$，即系统要访问这些设备，都是通过 $\text{0x80000000}$ 以下的物理地址直接访问，但通过这样的物理地址访问设备就不会经过 RAM 了。&#xA;内核空间的虚拟地址是直接映射到物理地址的，例如 KERNBASE=0x80000000，虚拟地址和物理地址都是这个值，可以理解为虚拟地址等于物理地址。&#xA;但是有几个内核虚拟地址不是直接映射的，如下图所示：&#xA;trampoline page（蹦床页面），它映射在虚拟地址空间的顶部，user page table 具有相同的映射，即不论 kernel page table 还是 user page table，trampoline page 的虚拟地址都是在虚拟地址空间的顶部； kernel stack page，每个进程都有自己的 kernel stack，会映射到虚拟地址空间中比较高的那个 kernel stack，这样可以利用到 kernel stack 下方的那个 guard page。Guard page is invalid!</description>
    </item>
    <item>
      <title>Xv6 Lab2: System calls</title>
      <link>http://localhost:1313/posts/tech/xv6-lab2.zh/</link>
      <pubDate>Sat, 01 Jul 2023 15:15:38 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/xv6-lab2.zh/</guid>
      <description>系统调用 Lab1 主要是基于提供的系统调用接口来编写一些小工具程序，而 Lab2 则是要我们自己实现系统调用，并提供系统调用的接口。&#xA;以本次 Lab 要我们实现的 trace 调用为例，说明一下系统调用的流程：&#xA;在 user/trace.c 的第 $15$ 行，调用了属于 system call 的 trace 函数，当前执行 make qemu 是无法成功的，因为我们还没有给用户提供接口。因此，我们需要在 user/user.h 里面添加系统调用 trace 的函数声明（prototype）。&#xA;我们需要在 user/usys.pl 中追加 entry(&amp;quot;trace&amp;quot;); 这一行，从而添加一个 trap entry，从而实现调用 trace 时会发生 trap，从而会执行 ECALL 指令，并且会将系统调用的接口的参数（这里就是 trace 的参数）的存入寄存器 a0、a1 等（从左往右第一个参数的地址存入 a0，依次类推），此外，还会将 trace 对应的系统调用号存入寄存器 a7。&#xA;之后控制权来到 kernel 中的 syscall 函数，它从 a7 中取出系统调用号，并执行系统调用号对应的 sys_func。&#xA;这里的系统调用号可以理解为数组索引，在本次 Lab 中需要我们修改 kernel/syscall.c 和 kenel/syscall.h 从而添加 trace 对应的系统调用号，以及内核中 trace 对应的 sys_trace 的实现）。&#xA;System call tracing 官网的提示其实是比较全面了，按提示处理，即可添加 trace 的系统调用接口：</description>
    </item>
    <item>
      <title>MIT 6.S081 操作系统组织架构</title>
      <link>http://localhost:1313/posts/tech/xv6-os-organization.zh/</link>
      <pubDate>Thu, 29 Jun 2023 18:59:04 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/xv6-os-organization.zh/</guid>
      <description>进程概述 64 位的 RISC-V 的 VAS 是 39 位的，即 VA 只有 39 位，而 Xv6 则只有 38 位，最大虚拟地址为 #define MAXVA 0x3fffffffff。&#xA;VAS 的顶端，即最高位存放了两个 page，一个是用于 trampoline，一个用于 mapping the process&amp;rsquo;s trapframe。 Xv6 使用这两个 page 来切换到内核以及返回。&#xA;进程的状态被定义在 kernel/proc.h 的结构体 struct proc 所描述，进程在内核中最重要的信息就是它的 page table、 kernel stack 以及运行状态（run state）。&#xA;A process can make a system call by executing the RISC-V ecall instruction. This instruction raises the hardware privilege level and changes the program counter to a kernel-defined entry point.</description>
    </item>
    <item>
      <title>异常控制流（Exceptional Control Flow, ECF）</title>
      <link>http://localhost:1313/posts/tech/exceptional_control_flow.zh/</link>
      <pubDate>Tue, 27 Jun 2023 15:41:06 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/exceptional_control_flow.zh/</guid>
      <description>异常控制流简介 从给处理器上电起，直到断电，程序计数器（PC）假设一个值的序列： $$ a_0, a_1, \cdots, a_{n - 1}$$&#xA;每个 $a_k$ 是某个相应的指令 $I_k$ 的地址，每次从 $a_k$ 到 $a_{k + 1}$ 的过渡称为控制转移（control transfer）。这样的控制转移序列叫做处理器的控制流（flow of control 或 control flow）。&#xA;最简单的控制流是一个平滑的序列，即 $I_k$ 和 $I_{k + 1}$ 在内存中是连续的。&#xA;现代系统通过使控制流发生突变来应对系统状态的变化。一般而言我们把这些突变称为异常控制流（Exceptional Control Flow, ECF）。&#xA;例如当前程序在执行地址 $a_k$ 对应的指令 $I_k$，正常情况下，下一个指令应该是应该是地址 $a_{k + 1}$ 对应的指令 $I_{a_{k + 1}}$，但是由于发生了 page fault，它转去执行内核态的缺页异常处理程序，对应指令 $I_j$，执行完 $I_j$ 之后，它又回来执行 $I_k$。&#xA;For example, at the hardware level, events detected by the hardware trigger abrupt control transfers to exception handlers.</description>
    </item>
    <item>
      <title>红黑树</title>
      <link>http://localhost:1313/posts/tech/red-black-tree.zh/</link>
      <pubDate>Mon, 26 Jun 2023 19:44:02 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/red-black-tree.zh/</guid>
      <description>自顶向下的 2-3-4 树 插入结点 2-3-4 树的插入算法，简而言之，就是在往下查找应该将待插入的 new_key 插入到何处的时候，一旦碰到 4- 结点，就将 4- 结点中间的 key 上溢，剩下的两个 key 作为两个 2- 结点，这个上溢的过程也是递归的，可以理解为向原先 4- 结点的父结点插入 4- 结点中间的这个 key，4- 结点剩下的部分作为两个 2- 结点。我们的这个分解算法，保证了4- 结点的父结点不会是 4- 结点。（这里可以用数学归纳法给出证明）&#xA;这样处理到最后，我们的 new_key 要插入的结点一定是 2- 结点或者 3- 结点，因此，我们可以直接插入。&#xA;要实现这个插入算法，我们需要：&#xA;将 4- 结点表示为由三个 2- 结点组成的一个平衡的子树，根结点和两个子结点都用 red link 连接； 在向下的过程中分解所有 4- 结点并进行颜色转换； 和插入操作一样，在向上的过程中用旋转将 4- 结点配平； 但实际上，我们只要移动 put 方法中的三行代码就能由 2-3 树对应的红黑树操作转移到 2-3-4 树对应的红黑树操作；即将 FlipColors 语句（以及 if 判断）移动到 nullptr 测试之后，递归调用之前，如下：&#xA;void Put(int key, int val) { root_ = Put(key, val, root_); root_-&amp;gt;color_ = kBlack; // 根结点的颜色一定是黑色！ } auto Put(int key, int val, Node *h) -&amp;gt; Node * { // h 表示我们往以 h 为根结点的树中插入结点 if (h == nullptr) { return new Node(key, val, 1, kRed); } if (isRed(h-&amp;gt;left_) &amp;amp;&amp;amp; isRed(h-&amp;gt;right_)) { // 左右子结点都是红色，翻转颜色 // 即碰到 4- 结点就分解成两个 2- 结点 FlipColors(h); } if (key &amp;lt; h-&amp;gt;key_) { h-&amp;gt;left_ = Put(key, val, h-&amp;gt;left_); } else if (key &amp;gt; h-&amp;gt;key_) { h-&amp;gt;right_ = Put(key, val, h-&amp;gt;right_); } else { h-&amp;gt;val_ = val; } if (!</description>
    </item>
    <item>
      <title>左倾红黑树 （LLRB）</title>
      <link>http://localhost:1313/posts/tech/left-lean-red-black-tree.zh/</link>
      <pubDate>Sat, 24 Jun 2023 13:36:26 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/left-lean-red-black-tree.zh/</guid>
      <description>简介 红黑树是平衡二叉查找树的一种，前面我们提到，非平衡的 BST，在只有随机插入和查询的情况下，时间复杂度是 $O(\log n)$ 的，然而，如果同时存在随机插入和随机删除，那么时间复杂度会退化到 $O(\sqrt n)$，这是我们无法接受的。&#xA;红黑树在插入和删除时，会维持树的平衡，即保证树的高度在 $[\log n, \log(n + 1)]$，理论上极端情况可能树高最大会到达 $2 * \log n$，实际上很难遇到（尽管这样，还是保证了 $O(\log n)$ 的增删查改时间复杂度。&#xA;红黑树其实是 2-3 查找树或者 2-3-4 查找树的一种二叉树的实现方式。其中基于 2-3 树实现的红黑树被称为左倾红黑树（Left-Leaning Red-Black Trees, LLRB），基于 2-3-4 树实现的就是普通的红黑树，左倾红黑树实现起来比红黑树更简单一些（《算法 第四版》里面也主要讲的左倾红黑树），因此先讲左倾红黑树。&#xA;2-3 查找树 在普通的二叉树中，非叶子结点可以有一个或者两个子结点，如果没有子结点，那么就是叶子结点。&#xA;而 2-3 查找树的限制要严格很多。我们将拥有一个 key 和两个链接 的结点称为 2- 结点，拥有两个 key 和三个链接的结点称为 3- 结点。&#xA;2- 结点含有一个 key，两个 link； 3- 结点含有两个不同的 key，三个 link。 3- 结点含有两个 key（$key_1 &amp;lt; key_2$），三个链接，左链接指向 2-3 树中的 key 都小于 $key_1$，中间链接指向的 2-3 树中的 key 都满足 $key_1 &amp;lt; key &amp;lt; key_2$，右链接指向的 2-3 树中的 key 都大于 $key_2$。</description>
    </item>
    <item>
      <title>树状数组</title>
      <link>http://localhost:1313/posts/tech/binary_index_tree.zh/</link>
      <pubDate>Fri, 23 Jun 2023 23:55:33 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/binary_index_tree.zh/</guid>
      <description>引入 数装数组是一种支持单点修改和区间查询的数据结构。&#xA;这里的区间查询一般指求和。&#xA;普通树状数组维护的信息以及运算要满足结合律并且可以差分。&#xA;定义 考虑下标从 $1$ 开始的数组 $a[1]\sim a[8]$，如下图所示：&#xA;我们可以发现：&#xA;$c[2]$ 管辖 $\sum\limits_{i = 1}^2 a[i]$； $c[4]$ 管辖 $\sum\limits_{i = 1}^4 a[i]$； $c[6]$ 管辖 $\sum\limits_{i = 5}^6 a[i]$； $c[8]$ 管辖 $\sum\limits_{i = 1}^8 a[i]$； 即 $c[x]$ 管辖 $\sum\limits_{i = x - (x \text{AND} -x) + 1}^x a[i]$。例如 $6\text{AND}(-6) + 1 = 5$。&#xA;同时我们定义 $\text{lowbit}(x) = x \text{AND} -x$&#xA;使用 那么如何使用树状数组呢，第一步是初始化，我们先假定原数组也是下标从 $1$ 开始，从 $0$ 开始那么做相应变换即可。&#xA;初始化 我们先令 $c[i] = 0$，然后遍历 $a[j]$，每次遍历相当于是（假设原数组元素均为 $0$，然后将其值加上 $a[i]$），即初始化树状数组相当于是做了 $n$ 次单点修改。</description>
    </item>
    <item>
      <title>二叉搜索树</title>
      <link>http://localhost:1313/posts/tech/bst.zh/</link>
      <pubDate>Fri, 23 Jun 2023 15:08:23 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/bst.zh/</guid>
      <description>二叉搜索树 二叉搜索树（Binary Search Tree，BST）是指一颗空树或者有下列性质的二叉树：&#xA;若任意节点的左子树不为空，那么左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不为空，那么右子树上所有节点的值均小于它的根节点的值； 任意节点的左、右子树也分别为二叉搜索树； 二叉树的定义是从一个递归的角度来定义的，验证二叉树其实很简单，即中序遍历二叉树，节点的值从严格递增。换言之，二叉搜索树也可以定义成中序遍历时节点值严格递增的二叉树。&#xA;BST 的删除 对树的定义，我们采取 Leetcode 中的定义：&#xA;struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode() : val(0), left(nullptr), right(nullptr) { } TreeNode(int x) : val(x), left(nullptr), right(nullptr) { } TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) { } }; 首先，我们定义两个辅助函数 TreeNode *delMax(TreeNode *root, int key); 和 TreeNode *delMin(TreeNode *root, int key);，分别表示删除二叉树中的值最大的节点和值最小的节点。还需要辅助函数 int getMin(TreeNode *root); 和 int getMax(TreeNode *root)。&#xA;getMin 和 getMax 自不必多说，以 delMax 为例，都是利用递归进行处理，递归返回的是当前以 root 为根节点的树，删除了最大值之后的 root。递归终止条件即 root-&amp;gt;right == nullptr，说明找到了树的最大值，此时返回 root-&amp;gt;left。（以避免左子树不为空的情况，左子树为空则相当于返回了 nulltpr）</description>
    </item>
    <item>
      <title>Linux 动态内存分配</title>
      <link>http://localhost:1313/posts/tech/linux_memory_allocate.zh/</link>
      <pubDate>Tue, 20 Jun 2023 15:29:09 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/linux_memory_allocate.zh/</guid>
      <description>动态内存分配器 进程中名为 heap 的 VM area 就是由动态内存分配器（dynamic memory allocator）来维护的。Heap 会向高地址（向上）增长。对每个进程，内核维护着一个名为 brk 的变量，该变量指向 Heap 的顶部，如下图所示：&#xA;Allocator 将 Heap 视为一组不同大小的 block 组成的集合来维护。这里 block 和 chunk 的概念是等价的，该 block 要么是已分配的（allocated），要么是空闲的（free）。&#xA;Each block is a contiguous chunk of virtual memory that is either allocated or free.&#xA;Allocator 可以分为显式分配器（explicit allocator）和隐式分配器（implicit allocator）。&#xA;显示分配器要求应用显示地释放任何已分配的块，分配也需要手动分配。例如 C 中的 malloc 和 free，C++ 中的 new 和 delete； 隐式分配器又被称为垃圾收集（garbage collection），例如 Java、C#。 malloc 和 free $32$ 位系统中，malloc 返回的地址总是 $8$ 的倍数，即 malloc 返回的地址的最低三位总是 $0$，亦即 malloc 分配的 block 至少占据 $8$ 的倍数个 byte；而 $64$ 位系统中，malloc 返回的地址总是 $16$ 的倍数。</description>
    </item>
    <item>
      <title>Linux 虚拟内存系统</title>
      <link>http://localhost:1313/posts/tech/linux_virtual_memory.zh/</link>
      <pubDate>Sun, 18 Jun 2023 14:50:57 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/linux_virtual_memory.zh/</guid>
      <description>Linux 虚拟内存系统 首先，对 Linux 的虚拟内存系统做一个概述，以了解一个实际的操作系统是如何组织虚拟内存，以及如何处理缺页（page fault）的。&#xA;Linux 位为每个进程维护了一个单独的虚拟地址空间，形式如下：&#xA;可以看到，虚拟地址空间可以分为内核虚拟内存空间和用户虚拟内存空间两部分，实际上，$64$ 位系统的虚拟空间划分是这样的：&#xA;我们可以看到，在用户内存空间和内核内存空间之间还有一大片的“未定义”的区域，这是为什么呢？（注意，后续图片将有灵魂画手出没！）。&#xA;之前我们提到，AMD 制定的 $64$ 位 CPU 架构时，虽然是 $64$ 位的，即总的虚拟地址空间是 $64$ 位的，但实际上，用到的虚拟地址其实只有其中的低 $48$ 位。&#xA;当我们把 addr_val 解释为一个虚拟地址时，我们使用的真正的虚拟地址，其实只有它的低 $48$ 位，（由 AMD 设计 CPU 架构的时候规定，其实 $48$ 位也完全够用了），后 $16$ 位的值会与 addr_val 的第 $47$ 位保持一致（全 $0$ 或者全 $1$），全 $0$ 表示该虚拟地址处于当前虚拟地址空间的用户态部分，全 $1$ 表示处于内核态部分。&#xA;换言之，虚拟地址的高 $16$ 位是由 CPU 在生成要访问的虚拟地址时，先生成低 $48$ 位的虚拟地址，再根据第 $47$ 位的值是 $0$ 还是 $1$，判断地址属于内核虚拟地址空间还是用户虚拟地址空间（或者说进程虚拟地址空间），再生成虚拟地址的高 $16$ 位。&#xA;如下图所示：&#xA;Linux 虚拟内存区域（area） Linux organizes the virtual memory as a collection of areas (also called segments).</description>
    </item>
    <item>
      <title>关于我</title>
      <link>http://localhost:1313/posts/blog/about_me.zh/</link>
      <pubDate>Wed, 14 Jun 2023 15:39:28 +0800</pubDate>
      <guid>http://localhost:1313/posts/blog/about_me.zh/</guid>
      <description>我写博客的初心很简单，一是记录一些软件的配置过程（防止第二次配置的时候又抓瞎）；二是记录下一下自己学习过程中的一些心得体会。&#xA;在 高乙超的博客 中，我曾经看到一句话，叫 &amp;ldquo;To learn, read; To know, write; To master, teach&amp;rdquo;。&#xA;过去二十年里，在学习的过程中，我一直是作为一个输入方，应付考试倒是没啥问题，但也仅此而已了。&#xA;为了更好地体会和领悟这些知识，我决定写写博客，既是做笔记，也是对自己的所学的一种整理和输出，也希望能有更多同道者看到，从而一起交流学习、共同进步。</description>
    </item>
    <item>
      <title>线段树</title>
      <link>http://localhost:1313/posts/tech/seg_tree.zh/</link>
      <pubDate>Tue, 13 Jun 2023 19:44:22 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/seg_tree.zh/</guid>
      <description>引入 线段树是算法竞赛中常用的用来维护区间信息的数据结构。&#xA;树状数组可以在 $O(\log n)$ 的时间内实现单点修改、区间查询（求和、求最值、求异或等）；而线段树还可以在 $O(\log n)$ 时间内实现区间修改操作，例如将 $[L, R]$ 区间范围内的值都加上一个常数，乘以一个常数，或者都置为某个数。&#xA;常规线段树 结构 就我的理解而言，常规的线段树能实现的功能其实与树状数组没什么区别，都只能在 $O(\log n)$ 时间内实现单点修改和区间查询。&#xA;线段树的构造：给定一个区间 $[L, R]$，取 $mid = L + (R - L) / 2$，将它划分为 $[L, mid]$ 和 $[mid + 1, R]$ 两个区间，如此递归地划分，直到区间长度为 $1$ 为止，这些父区间和划分为左右两边的子区间，在组织结构上很像二叉树的父结点和子结点，这也就是线段树的名字由来。&#xA;我们这里以区间求和为例，线段树的每个结点对应着相应的线段上的点的和，以数组 $a = {1,2,3,4,5,6,7,8,9,10}$ 为例，线段树的结构如图所示：&#xA;可以看到，线段树存储的基础形式是数组，与二叉堆的存储方式一致，假设当前父结点的编号为 $p$，那么左儿子的编号为 $2 * p$，右儿子的编号为 $2 * p + 1$，结点的值为对应区间的和。&#xA;构建线段树的方式其实与“求以该节点为根节点的子树的和”类似，递归处理是很容易的。&#xA;代码实现：&#xA;void Build(int idx, int l, int r, vector&amp;lt;int&amp;gt; &amp;amp;nums) { if (l == r) { seg[idx] = nums[l]; return; } int mid = l + (r - l) / 2; Build(2 * idx, l, mid, nums); // 递归构建左子树 Build(2 * idx, mid + 1, r, nums); // 递归构建右子树 seg[idx] = seg[2 * idx] + seg[2 * idx + 1]; // 更新 seg[idx] } 区间查询 线段树的区间查询，其实只要掌握了递归，就很好理解了。</description>
    </item>
    <item>
      <title>数组形式组织的树</title>
      <link>http://localhost:1313/posts/tech/tree_in_array.zh/</link>
      <pubDate>Mon, 12 Jun 2023 13:47:07 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/tree_in_array.zh/</guid>
      <description>引入 在 LeetCode 中，二叉树一般是以链表结点的形式组织的，定义如下：&#xA;struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x): val(x), left(nullptr), right(nullptr) {} }; 其实也可以用数组的形式组织，即使用 $parent$ 数组，$y = parent[x]$ 说明 $y$ 是 $x$ 的父结点，根结点的父结点为 $-1$，表示父结点不存在。&#xA;最近公共祖先 链表形式 对链表形式树，求最近公共祖先可以使用递归很方便的解决：&#xA;/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) {} * }; */ class Solution { public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) { if (root == nullptr || root == p || root == q) { return root; } TreeNode *left = lowestCommonAncestor(root-&amp;gt;left, p, q); TreeNode *right = lowestCommonAncestor(root-&amp;gt;right, p, q); if (left !</description>
    </item>
    <item>
      <title>CPU 缓存一致性：MESI</title>
      <link>http://localhost:1313/posts/tech/cache_mesi.zh/</link>
      <pubDate>Wed, 07 Jun 2023 10:36:47 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/cache_mesi.zh/</guid>
      <description>概述 MESI（也称伊利诺斯协议）是一种广泛使用的支持 write-back 策略的缓存一致性协议。&#xA;MESI 状态 我们假设 CPU 中共有 $k$ 个核； CPU 中每个 cacheline 使用 $4$ 种状态进行标记：&#xA;状态 介绍 所有核中该状态的个数 MODIFIED 实际上是 exclusive dirty，说明该核的缓存数据被修改了，且并未写入到更低一层存储中；当某个核的缓存处于该状态时，其余核的对应 cacheline 均为 INVALID 1 EXCLUSIVE 实际上是 exclusive clean，说明该核的缓存刚从更低一层存储中读取到了最新的数据；当某个核的缓存处于该状态时，其余核的对应 cacheline 均为 INVALID 1 SHARED 实际上是 shared clean，说明多个核的缓存从更低一层存储中读到的数据都是最新的，处于该状态的核的数量一定 $\geq 2$，其余核的对应 cacheline 均为 INVALID $\geq 2$ INVALID 说明该核的 cacheline 无效 状态切换 我们以四个核为例，用四元组如 $(M, I, I, I)$ 表示四个核的 cacheline 状态，假设只操作第一个核的 cacheline：&#xA;执行读操作 $(M,I,I,I)$ 执行读，状态仍为 $(M, I, I, I)$； $(E,I,I,I)$ 执行读，状态仍为 $(E, I, I, I)$； $(S,S,I,I)$ 执行读，状态仍为 $(S, S, I, I)$； $(I,M,I,I)$ 执行读，将第二个核的 cacheline 的数值 $val$ 写入内存，然后更新第一个核的 cacheline 的值为 $val$，状态切换为 $(S,S,I,I)$； $(I,E,I,I)$ 执行读，更新第一个核的 cacheline 为第二个核的数值 $val$，状态切换为 $(S,S,I,I)$； $(I,S,S,I)$ 执行读，更新第一个核的 cacheline 为第二个或第三个核的数值 $val$，状态切换为 $(S,S,S,I)$； $(I,I,I,I)$ 执行读，从内存中读取对应的地址的数值 $*addr$ 到 cacheline，状态切换为 $(E, I, I, I)$； 执行写操作 $(M,I,I,I)$ 执行写，状态仍为 $(M, I, I, I)$； $(E,I,I,I)$ 执行写，状态变为 $(M, I, I, I)$； $(S,S,I,I)$ 执行写，将其他所有状态为 $S$ 的 cacheline 的状态全都设置为 $I$，状态变为 $(M, I, I, I)$； $(I,M,I,I)$ 执行写，将第二个核的 cacheline 的数值 $val$ 写入内存（为了防止 ABA 问题，这里为什么要写回 TODO(zwyyy)，是否和指令原子性有关），状态变为 $I$，然后更新第一个核的 cacheline 的值为 $val$，再更新值为待写入的值 $write$_$value$，状态切换为 $(M,I,I,I)$； $(I,E,I,I)$ 执行写，更新第一个核的 cacheline 为第二个核的数值 $val$，将第二个核的状态设为 $I$，状态切换为 $(M,I,I,I)$； $(I,I,I,I)$ 执行写，将 $write$_$val$ 写到 cacheline 中，状态切换为 $(M, I, I, I)$； 执行 evict 操作 </description>
    </item>
    <item>
      <title>跳表</title>
      <link>http://localhost:1313/posts/tech/skiplist.zh/</link>
      <pubDate>Tue, 06 Jun 2023 18:28:54 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/skiplist.zh/</guid>
      <description>跳表介绍 跳表是一种数据结构，使得包含 $n$ 个元素的有序序列的查找和插入操作的平均时间复杂度都是 $O(\log n)$，与红黑树、AVL 性能类似。&#xA;跳表的快速查询效果是通过维护一个多层次的链表实现的，且与前一层（下面一层）的链表元素相比，每一层链表中的元素的数量更少，一开始，算法在最上层（也是最稀疏的一层）查找，直到要查询的元素在该层相邻的两个元素中间。这时，算法将跳转到下一个层，重复刚才的搜索，直到找到需要查找的元素为止如下图所示：&#xA;层数索引从低到高逐渐递增。&#xA;描述 跳表是按照层构建的，跳表的最底层是一个普通的有序链表，每个更高层都是下层列表的子列表，相当于下层列表的快速通道，这里可以类比一下 B树 或者 B+树。&#xA;在跳表中，第 $i$ 层的元素会有概率 $p$ 出现在第 $i + 1$ 层中（$p$ 通常取 $\frac{1}{2}$ 或者 $\frac{1}{4}$），每个元素平均出现在 $\frac{1}{1 - p}$ 个列表中。&#xA;一般认为，列表有 $log_{\frac{1}{p}}n$ 层，在后面的实现中，我们固定了列表的层数为 $klevel = 8$，动态层数的列表实现起来比较复杂。&#xA;在查找目标元素时，从顶层列表、头元素起步。算法沿着每层链表搜索，直至找到一个大于或等于目标的元素，或者到达当前层列表末尾：&#xA;如果该元素等于目标元素，则表明该元素已被找到； 如果该元素大于目标元素或已到达链表末尾，则退回到当前层的上一个元素，然后转入下一层进行搜索。 每层链表中预期的查找步数最多为 $\frac{1}{p}$，而层数为 $\log_{\frac{1}{p}}n$，因此查找的总体步数为 $\frac{\frac{1}{p}}{\log_{\frac{1}{p}}n}$，$p$ 是常数，因此总体查找的时间复杂度为 $O(\log n)$ 的。&#xA;跳跃列表不像平衡树等数据结构那样提供对最坏情况的性能保证：由于用来建造跳跃列表采用随机选取元素进入更高层的方法，在小概率情况下会生成一个不平衡的跳跃列表（最坏情况例如最底层仅有一个元素进入了更高层，此时跳跃列表的查找与普通列表一致）。&#xA;但是在实际中它通常工作良好，随机化平衡方案也比平衡二叉查找树等数据结构中使用的确定性平衡方案容易实现。&#xA;实现 以 1206. Design Skiplist (Hard) 为例，进行跳表的简单实现。&#xA;由上述图片，我们可以构想出结点的数据结构：&#xA;结点值 $val$； 存储当前结点每一层的 $next_$ 指针（这里使用 vector 存储）。 为了方便理解，我们其实可以把每个结点都看成图中 $klevel$ 高度，只是我们只画出来 $next_[i]$ 不为 $nullptr$ 的对应层罢了。 const int klevel = 8; struct Node { int val_; vector&amp;lt;Node *&amp;gt; next_; // next[i] 表示当前结点在第 i 层的 next，i 从 0 开始 Node(int val) : val_(val), next_{klevel, nullptr} { // 初始化 } }; 之后，我们使用一个辅助函数 void Find(int target, veoctor&amp;lt;Node *&amp;gt; pre); 来存储每一层中：满足值小于 $target$ 并且值最大的结点。</description>
    </item>
    <item>
      <title>数位 DP</title>
      <link>http://localhost:1313/posts/tech/number_dp.zh/</link>
      <pubDate>Tue, 06 Jun 2023 10:37:04 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/number_dp.zh/</guid>
      <description>引入 数位是指把一个数字按照个、十、百、千、万等等一位一位地拆开，关注它每一位上的数字。如果拆的是十进制数，那么每一位数字都是 $0\sim 9$。&#xA;数位 DP 一般是用来解决一类特定问题，以 1012. Numbers With Repeated Digits (Hard) 为例，这一类问题的特征非常明显&#xA;要求统计满足一定条件的数的数量； 这些条件经过转化后可以使用“数位”的思想去理解和判断； 输入会提供一个数字区间（有时候只提供上界）来作为统计的限制； 上界很大（例如 $10^{22}$），暴力枚举会超时。 思路 对 1012. Numbers With Repeated Digits (Hard)，思路如下：&#xA;首先，正难则反，我们可以考虑 $[1, n]$ 范围内无重复数字的正整数的个数，记为 $res$，然后最终结果就是 $n - res + 1$（至于为什么还要再加上 $1$，后面会说明）。&#xA;因此问题转化为求 $[1, n]$ 范围内无重复数字的正整数的个数，符合上述的数位 DP 的特征，我们可以从记忆化搜索的角度去考虑，首先将 $n$ 转化为对应的字符串，对字符串的每一位，枚举每一位可能的数，如果最后组成的数字满足 $num &amp;lt; n$，那么 $res += 1$，这里很容易想到 dfs(string &amp;amp;str, int idx, int mask)，$mask$ 以二进制的形式表示 $0\sim 9$ 范围内的数是否被选择过；&#xA;但是仅仅是这样，我们不能方便的判断当前组成的数字是否满足 $num &amp;lt; n$，因此，我们需要一个额外的参数 $is_limit$。例如对数字 $n = 12345$，如果前面已经选择的数字为 $123$，那么对本次枚举，$is_limit$ 为 $true$，即数字只能选择 $0\sim4$，又因为 $1,\ 2,\ 3$ 已经选择了，$mask = 14$，因此只有 $0,\ 4$ 可以选，事实上，我们可以发现，在递归的过程中，当且仅当当前 $is_limit$ 为 $true$，且当前选择的数字与对应数位上的数字相等时，更深一层递归的 $is_limit$ 仍为 $true$，至此，递归函数为 dfs(string &amp;amp;str, int idx, int mask, bool is_limit)；</description>
    </item>
    <item>
      <title>二分答案</title>
      <link>http://localhost:1313/posts/tech/binary_search.zh/</link>
      <pubDate>Thu, 01 Jun 2023 15:53:13 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/binary_search.zh/</guid>
      <description>概述 二分答案即利用二分查找来得到答案，一般情况下，左边界 $left$ 是 $0$ 或者 $1$；右边界 $right$ 则视题目条件而定，取一个很大的数，然后利用二分查找的思想，来找到答案。&#xA;二分答案的要求 如果题目能够使用二分答案的思想来解决，那么 $[left, right]$ 范围内，要满足二段性，即对 $[left, res]$ 满足条件 $A$，而 $(res, right]$ 不满足条件 $A$，并且 res 的取值范围是连续的。&#xA;适用情况 如果题目要求满足 xxx 条件下的最大值或者最小值，就可以考虑二分答案，特别的，如果题目要求最小化的最大值或者最大化的最小值，那么要首先考虑使用二分答案。&#xA;例题 2517. 礼盒的最大甜蜜度 (Medium)&#xA;class Solution { public: int Bsearch(int target, vector&amp;lt;int&amp;gt; &amp;amp;price, int left) { int right = price.size(); while (left &amp;lt; right) { int mid = left + (right - left) / 2; if (price[mid] &amp;lt; target) { left = mid + 1; } else { right = mid; } } return left; } bool Check(int mid, vector&amp;lt;int&amp;gt; &amp;amp;price, int k, int n) { int start = 0; for (int i = 0; i &amp;lt; k - 1; ++i) { start = Bsearch(price[start] + mid, price, start); // cout &amp;lt;&amp;lt; start &amp;lt;&amp;lt; &amp;#34; start\n&amp;#34;; if (start &amp;gt;= n) { return false; } } return true; } int maximumTastiness(vector&amp;lt;int&amp;gt; &amp;amp;price, int k) { // 先排序，然后考虑是二分答案还是双指针 sort(price.</description>
    </item>
    <item>
      <title>LRU 算法与 LFU 算法</title>
      <link>http://localhost:1313/posts/tech/lru_lfu.zh/</link>
      <pubDate>Wed, 31 May 2023 16:36:04 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/lru_lfu.zh/</guid>
      <description>算法介绍 LRU LRU 全称是 Least Recently Used，即最近最久未使用算法。&#xA;LRU 根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高，它是页面置换算法的一种，也常用于缓存设计。&#xA;LFU LFU 全称是 Least Frequently Used，根据频率来选择要淘汰的元素，即删除访问频率最低的元素，如果两个元素的访问频率相同，则淘汰访问频率最低的元素中最久没有被访问的元素。&#xA;数据结构 不管是 LRU 还是 LFU 算法，我们都需要使用到双向链表作为基础数据结构，由于 LRU 与 LFU 涉及的对双向链表的元素的操作比较复杂，还涉及对链表结点的其他操作，因此选择自己手写一个简单的双向链表，同时复习双向链表的实现（阿里一面就被问到了，半天没写对😅）。&#xA;这里根据 LRU 和 LFU 的需要，简单封装了删除结点、尾部插入结点、和判断双向链表是否为空三个函数，很大程度上简化了 LRU 和 LFU 的实现，降低了写算法实现代码的出错概率。&#xA;struct Node { Node() { } Node(int val, int key) : val_(val), key_(key), next_(nullptr), pre_(nullptr) { } int val_; int freq_; Node *next_; Node *pre_; int key_; }; struct List { Node *vhead_; // 虚拟头结点 Node *vtail_; // 虚拟尾结点 int size_ = 0; // 链表中有效结点的数量 List() : vhead_(new Node()), vtail_(new Node()) { vhead_-&amp;gt;next_ = vtail_; vtail_-&amp;gt;pre_ = vhead_; vhead_-&amp;gt;pre_ = nullptr; vtail_-&amp;gt;next_ = nullptr; } ~List() { delete vtail_; delete vhead_; vhead_ = nullptr; vtail_ = nullptr; } void Insert(Node *node) { // 双向链表的插入, node 表示待插入结点，插入作为双向链表的尾结点 node-&amp;gt;pre_ = vtail_-&amp;gt;pre_; vtail_-&amp;gt;pre_-&amp;gt;next_ = node; vtail_-&amp;gt;pre_ = node; node-&amp;gt;next_ = vtail_; ++size_; } void Delete(Node *node) { // node 指向待删除结点 node-&amp;gt;next_-&amp;gt;pre_ = node-&amp;gt;pre_; node-&amp;gt;pre_-&amp;gt;next_ = node-&amp;gt;next_; --size_; } bool Empty() { return size_ &amp;lt;= 0; } }; LRU 实现 对于 LRU 的实现，我们需要借助两个数组结构哈希表和双向链表来组成一个新的数据结构。我们利用哈希表实现 $O(1)$ 时间复杂度的查找，获取元素的 val 以及在双向链表中的位置；利用双向链表实现 $O(1)$ 时间复杂度内的元素插入和删除。</description>
    </item>
    <item>
      <title>字典树</title>
      <link>http://localhost:1313/posts/tech/trie.zh/</link>
      <pubDate>Mon, 29 May 2023 09:54:58 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/trie.zh/</guid>
      <description>定义 字典树（Trie），是一个像字典一样的树，又称前缀树。&#xA;可以高效的查询某个字符串是否在一组给定的字符串中，或者说查询某个单词是否在字典中。&#xA;字典树的查询时间复杂度可以认为是 $O(l)$，其中 $l$ 为待查询单词的长度。&#xA;引入 字典树示意图：&#xA;可以发现，这棵字典树用边来代表字母，而根结点到树上面某一个节点的路径就代表一个字符串，例如 $1\rightarrow 4\rightarrow 8\rightarrow 12$ 表示的就是字符串 caa，如果结点 $12$ 对应的 end_ 字段的值为 $true$，说明 caa 是字典树中一个完整的字符串，否则只是一个前缀。&#xA;trie 的结构非常好懂，我们用 $\delta(u,c)$ 表示结点 $u$ 的 $c$ 字符指向的下一个结点，或着说是结点 $u$ 代表的字符串后面添加一个字符 $c$ 形成的字符串的结点。（ $c$ 的取值范围和字符集大小有关，不一定是 $0\sim 26$ 。）&#xA;字典树的实现 这里放一个简单的前缀树的类的实现，&#xA;struct Trie { int nex[10000][26], cnt; // nex 的第一维度表示前缀树的结点数量，与上面的图相对应 bool end[10000]; // 该结点结尾的字符串是否存在 void insert(char *s, int l) { // 插入字符串 int p = 0; for (int i = 0; i &amp;lt; l; i++) { int c = s[i] - &amp;#39;a&amp;#39;; if (!</description>
    </item>
    <item>
      <title>ELF 文件结构分析</title>
      <link>http://localhost:1313/posts/tech/elf_file_structure.zh/</link>
      <pubDate>Sun, 28 May 2023 15:59:11 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/elf_file_structure.zh/</guid>
      <description>目标文件的格式 目前，Linux 平台流行的 可执行文件（Executable）主要包含以下格式：&#xA;Linux 下的 ELF（Executable Linkable Format），注意这里是二进制文件其内容的组织格式，与后缀无关； 目标文件是源代码经过编译后但是未进行链接的那些中间文件（Linux 下为 .o 文件），它与可执行文件格式非常相似，一般与可执行文件一起采用同一种格式存储，Linux 下采用 ELF 文件格式。&#xA;动态链接库（Dynamic Linking Library）、静态链接库（Static Linking Library）均采用可执行文件格式存储，Linux 下均按照 ELF 格式存储。&#xA;Linux 下的 .so、.a； ELF 文件结构 CSAPP 上的 ELF 格式文件结构图：&#xA;更详细的 ELF 文件结构图：&#xA;可以看到，ELF 文件包含四个部分：&#xA;第一部分为 ELF Header； 第二部分为 Program Header Table，Relocatable object file 中该部分不存在，Executable object file 中该部分存在； 第三部分为 ELF Sections，包括 .text、.rodata、.data、.bss等； 第四部分为 ELF Section Header Table（或称节头表，后面以 sht 指代），注意 sht 不像 ELF Header 那样只有一块，它由多个 Section header table entry 组成。 ELF 的 16 进制内容 elf.</description>
    </item>
    <item>
      <title>字符串哈希算法</title>
      <link>http://localhost:1313/posts/tech/string_hash.zh/</link>
      <pubDate>Mon, 15 May 2023 11:52:54 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/string_hash.zh/</guid>
      <description>问题描述 考虑 1044. 最长重复子串 (Hard)，本题思路并不难，可以使用二分答案来解决，假设答案为 mid，那么长度大于 mid 的子串在 s 中只会出现一次，否则至少出现两次。&#xA;因此只需要考虑子串在 s 中的出现次数即可，比较直接的想法是使用 key 为 string 的 unordered_map，然而 unoredere_map 自带的哈希函数，其时间复杂度和空间复杂度都很高，为 $O(len)$，因此，需要一个简单一点的哈希函数。&#xA;字符串哈希 参照宫水三叶大佬的 字符串哈希。&#xA;我们需要使用一个比字符串 s 略长的哈希数组 vector&amp;lt;int&amp;gt; h(s.size() + 10)，以及次方数组 vector&amp;lt;int&amp;gt; p(s.size() + 10)。 对长度为 len 的数组，只需要利用前缀和思想 h[i + len] - h[i] * p[len] 即可在 $O(1)$ 时间内计算出哈希值。&#xA;其中 p[0] = 1，h[i] = h[i - 1] * P + s[i - 1]；p[i] = p[i - 1] * P。&#xA;$P$ 可以依次取 $131,\ 13131,\ 1313131$ 等，出现哈希碰撞就考虑取更大的质数。</description>
    </item>
    <item>
      <title>二进制下的补码、反码、原码——适用于有符号整数</title>
      <link>http://localhost:1313/posts/tech/2_complement.zh/</link>
      <pubDate>Mon, 08 May 2023 18:40:47 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/2_complement.zh/</guid>
      <description>简单定义 简单起见，我们这里只考虑三位二进制数所能表示的范围，即$[-4, -3, -2, -1, 0,\ 1,\ 2,\ 3]$。&#xA;机器数和真值 一个数在计算机中的二进制表现形式，就是这个数的机器数（相当于数的原码）。 例如，$-3$ 的机器数即为 $111$，$2$ 的机器数为 $010$。&#xA;机器数在考虑最高位为符号位的情况下，换算出来的值就是真值，例如 $111$ 的真值为 $-3$，而形式值为 $7$；$010$ 的形式值和真值都为 $2$。&#xA;原码、反码、补码 有符号整数的原码就是它的机器数，正数的反码与原码相同，而负数的反码则是符号位不变，其余位取反。&#xA;正数的补码（Complement）不变，负数的补码则是它的反码 $+1$，例如 $-1$ 的反码为 $110$，补码为 $111$；也可以说负数的补码是该负数的相反数的原码取反 $+1$。&#xA;为什么要用补码？ 使用补码可以解决减法运算的问题。 例如 $2 - 1 = 2 + (-1) = 010 + 111 = 001 = 1$ （$1001$ 去掉超出的最高位）。&#xA;使用原码或者反码都不好处理这个问题。&#xA;为什么补码会有这个效果？ 我们首先要意识到一点，$-1$ 的补码为 $111$，$111$ 对应的形式值为 $7$，而 $7 - (-1) = 8$。&#xA;例如，当我们使用 $2 - 1$ 时，相当于 $2 + 7 = 9$，然而，由于我们只能表示 $-4 \sim 3$ 这个范围内的所有数，大于 3 的数，就变成了 $9\mod 8 = 1$。</description>
    </item>
    <item>
      <title>C&#43;&#43; 虚函数与动态绑定</title>
      <link>http://localhost:1313/posts/tech/virtual_func.zh/</link>
      <pubDate>Sun, 23 Apr 2023 22:59:09 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/virtual_func.zh/</guid>
      <description>多态与动态绑定 为了实现 C++ 的多态，C++ 使用了动态绑定技术，该技术的核心是虚函数表（简称虚表）。&#xA;类的虚函数表 每个包含了虚函数的类都包含一个虚表，一个子类如果继承了包含虚函数的父类，那么这个类也拥有自己的虚表，例如&#xA;class A { public: virtual void vfunc1(); virtual void vfunc2(); void func1(); void func2(); private: int data1_, data2_; }; class B : public A { public: void vfunc1() override; void func1(); }; class C : public B { public: void vfunc2() override; void func2(); private: int data1_, data2_; }; A 包含虚函数 vfunc1() ，B 继承自 A，A 的虚表如图所示 虚表是一个指针数组，其元素是虚函数的指针，数组中的每个元素对应一个虚函数的指针。普通的函数（即非虚函数），其调用并不需要经过虚表，所以虚表的元素并不包括普通函数的函数指针。&#xA;虚函数指针的赋值发生在编译器的编译阶段，也就是在编译阶段，虚表就被构建出来了。&#xA;虚表指针 虚表是属于类的（有点像静态成员变量），而不属于某个具体的对象，一个类只需要一个虚表即可，同一个类的所有对象都使用同一个虚表。&#xA;为了指定对象的虚表，对象内部包含一个虚表的指针，来指向自己所使用的虚表。为了让每个包含虚表的类的对象都拥有一个虚表指针，编译器在类中添加了一个指针，*__vptr，用来指向虚表。这样，当类的对象在创建时便拥有了这个指针，且这个指针的值会自动被设置为指向类的虚表。&#xA;一个子类的父类如果包含虚函数，那么这个子类也拥有自己的虚表，所以这个子类的对象也包含一个虚表指针，用来指向它的虚表。 类 A 包括两个虚函数，故 A 的虚函数表包含两个指针，分别指向 A::vfunc1()和 A::vfunc2()。</description>
    </item>
    <item>
      <title>Cmake 基础教程</title>
      <link>http://localhost:1313/posts/tech/cmake_tutorial.zh/</link>
      <pubDate>Thu, 13 Apr 2023 13:42:31 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/cmake_tutorial.zh/</guid>
      <description>介绍 CMake是个一个开源的跨平台自动化建构系统，用来管理软件建置的程序，并不依赖于某特定编译器，并可支持多层目录、多个应用程序与多个库。 它用配置文件控制建构过程（build process）的方式和Unix的make相似，只是CMake的配置文件取名为CMakeLists.txt。CMake并不直接建构出最终的软件，而是产生标准的建构档（如Unix的Makefile或Windows Visual C++的projects/workspaces），然后再依一般的建构方式使用。&#xA;CmakeLists.txt 一个简单的CmakeLists.txt示例如下:&#xA;# 指定最小 CMake 版本要求 cmake_minimum_required(VERSION 3.9) # 设置项目名称 project(answer) #[[ 添加可执行文件 target，类似于原来 Makefile 的： answer: main.o answer.o main.o: main.cpp answer.hpp answer.o: answer.cpp answer.hpp CMake 会自动找到依赖的头文件，因此不需要特别指定， 当头文件修改的时候，会重新编译依赖它的目标文件。 #]] add_executable(answer main.cpp answer.cpp) #[[ 使用如下命令构建本项目： cmake -B build # 生成构建目录 cmake --build build # 执行构建 ./build/answer # 运行 answer 程序 #]] 其中cmake -B build命令中的-B参数是可选的，生成的文件会放到build文件夹中（没有该文件夹则会自动创建，最好原先没有）。&#xA;cmake --build build是执行构建，生成可执行文件，build指的是上一步-B参数指定的文件夹。&#xA;分离库文件情形下的CMakeLists.txt cmake_minimum_required(VERSION 3.9) project(answer) # 添加 libanswer 库目标，STATIC 指定为静态库 add_library(libanswer STATIC answer.</description>
    </item>
    <item>
      <title>快速选择算法</title>
      <link>http://localhost:1313/posts/tech/quick-select.zh/</link>
      <pubDate>Tue, 11 Apr 2023 19:55:41 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/quick-select.zh/</guid>
      <description>问题描述 给定一个长度为$n$的数组，如何在$O(n)$的时间复杂度内找到第$k$大的数。&#xA;思路 朴素的想法是先排序，然后直接找到第$k$个元素，时间复杂度为$O(n\log n)$。&#xA;我们可以利用快速排序的思想来解决这个问题，考虑快速排序的划分过程，在快速排序的“划分”结束后，数组$A_p \cdots A_r$被分成了$A_p\cdots A_q$和$A_{q+1}\cdots A_r$，此时可以按照左边元素的个数（$q-p+1$）和$k$的大小关系来判断是只在左边还是右边递归的求解。&#xA;代码 template &amp;lt;Typename T&amp;gt; // 类型T需要定义 &amp;lt; 运算 // arr 为查找范围数组，rk 为需要查找的排名（从 0 开始），len 为数组长度 T find_kth_element(T arr[], int rk, const int len) { if (len &amp;lt;= 1) { return arr[0]; } // 随机选择基准 const T pivot = arr[rand() % len]; // i 当前操作的元素 // j 第一个等于pivot的元素 // k 第一个大于pivot的元素 // 完成一趟三路快排，将序列分为： // 小于 pivot 的元素 ｜ 等于 pivot 的元素 ｜ 大于 pivot 的元素 int i = 0, j = 0, k = len; while (i &amp;lt; k) { if (arr[i] &amp;lt; pivot) { swap(arr[i++], arr[j++]); } else if (arr[i] &amp;gt; pivot) { swap(arr[i], arr[--k]); } else { ++i; } } // 根据要找的排名与两条分界线的位置，去不同的区间递归查找第k大的数 // 如果小于pivot的元素个数比k多，则第k大的元素一定是一个小于pivot的数 if (rk &amp;lt; j) { return find_kth_element(arr, rk, j); } else if (rk &amp;gt;= k){ // 否则，如果小于pivot和等于pivot的元素加起来也没有k多 // 则第k大的元素一定是一个大于pivot的元素 return find_kth_element(arr + k, rk - k, len - k); } else { // 否则，pivot就是第k大的元素 return pivot; } } 优化：中位数的中位数 中位数中的中位数（英文：Median of medians），提供了一种确定性的选择划分过程中分界值的方法，从而能够让找第$k$大的数算法在最坏情况下也能实现线性时间复杂度。</description>
    </item>
    <item>
      <title>拓扑排序</title>
      <link>http://localhost:1313/posts/tech/topo-sort.zh/</link>
      <pubDate>Mon, 10 Apr 2023 14:13:16 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/topo-sort.zh/</guid>
      <description>定义 拓扑排序（Topological sorting）要解决的问题是给一个有向图的所有节点排序。&#xA;这里直接使用OI-Wiki中举的例子来说明：&#xA;我们可以拿大学选课的例子来描述这个过程，比如学习大学课程中有：单变量微积分，线性代数，离散数学概述，概率论与统计学概述，语言基础，算法导论，机器学习。当我们想要学习 算法导论 的时候，就必须先学会 离散数学概述 和 概率论与统计学概述，不然在课堂就会听的一脸懵逼。当然还有一个更加前的课程 单变量微积分。&#xA;这些课程就相当于几个顶点$u$, 顶点之间的有向边$(u,v)$就相当于学习课程的顺序。显然拓扑排序不是那么的麻烦，不然你是如何选出合适的学习顺序。下面将介绍如何将这个过程抽象出来，用算法来实现。&#xA;但是如果某一天排课的老师打瞌睡了，说想要学习 算法导论，还得先学 机器学习，而 机器学习 的前置课程又是 算法导论，然后你就一万脸懵逼了，我到底应该先学哪一个？当然我们在这里不考虑什么同时学几个课程的情况。在这里，算法导论 和 机器学习 间就出现了一个环，显然你现在没办法弄清楚你需要学什么了，于是你也没办法进行拓扑排序了。因而如果有向图中存在环路，那么我们就没办法进行拓扑排序了。&#xA;因此我们可以说在一个[[DAG（有向无环图）]]中，我们将图中顶点以线性方式排序，使得对于任意顶点$u$到$v$的有向边$(u, v)$，都有$u$在$v$的前面。&#xA;或者说给定一个DAG，如果$i$到$j$有边，则认为$j$依赖于$i$，如果$i$到$j$有路径，则称$j$间接依赖于$i$； 拓扑排序的目标是将所有节点排序，使得在前面的节点不能依赖于排在后面的节点。&#xA;bfs 拓扑排序有广度优先搜索（bfs）和深度优先搜索（dfs）两种实现方式，这里我们先讨论bfs。&#xA;利用bfs实现拓扑排序需要根据节点的入度：&#xA;入度：有多少条边直接指向该节点&#xA;思路 起始时，将所有入度为$0$的点放入队列q_in0； 将队首元素出队，出队序列就是我们要求的拓扑序，对当前弹出的节点u，res.push_back(u)，遍历u的所有出度，即遍历所有由u直接指向的节点v，递减节点v的入度； 如果节点v的入度变为0，将节点v入队； 循环2、3流程直到队列为空； 如果res最后恰好有$n$个节点，说明原图为DAG，res中的节点序列即要求的拓扑序；否则说明图中存在环。&#xA;代码实现 vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; graph; int n = graph.size(); int in[n]; // 存储每个节点的入度 bool toposrot() { vector&amp;lt;int&amp;gt; res; queue&amp;lt;int&amp;gt; q_in0; for (int i = 0; i &amp;lt; n; ++i) { if (in[i] == 0) { q_in0.push(i); } } while (!</description>
    </item>
    <item>
      <title>kmp 算法</title>
      <link>http://localhost:1313/posts/tech/kmp.zh/</link>
      <pubDate>Mon, 27 Mar 2023 16:45:04 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/kmp.zh/</guid>
      <description>问题描述 kmp算法解决的是字符串匹配问题，即:字符串P是否是字符串S的子串？如果是，它出现在s的哪些位置？这里我们称 S 为主串，P 为模式串。&#xA;思路 首先是暴力匹配算法（Brute-Force算法），代码如下：&#xA;void BruteForce(string s, string p) { int len_s = s.size(), len_p = p.size(); for (int i = 0; i &amp;lt;= len_s - len_p; ++i) { int flag = true; for (int j = 0; j &amp;lt; len_p; ++j) { if (s[i + j] != p[j]) { flag = false; break; } } if (flag) { printf(&amp;#34;pos = %d\n&amp;#34;, i); } } } 易得时间复杂度的最坏情况是$O(mn)$的，其中$n$为s的长度，$m$为p的长度。</description>
    </item>
    <item>
      <title>并查集</title>
      <link>http://localhost:1313/posts/tech/dsu-oi-wiki.zh/</link>
      <pubDate>Wed, 22 Mar 2023 17:59:31 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/dsu-oi-wiki.zh/</guid>
      <description>引入 并查集是一种用于管理元素所属的集合的数据结构，其实现或者说表现为一片森林，其中，每棵树表示了一个集合，树中的节点表示对应的集合中的元素：&#xA;顾名思义，并查集支持两种操作：&#xA;合并（Union）：合并两个元素所属的集合（合并对应的树）； 查询（Find）：查询某个元素所属的集合（即查询对应的树的根节点），这可以用于判断两个元素是否属于同一个集合； 并查集在经过修改后还可以支持单个元素的移动、删除；使用动态开点线段树还可以实现可持久化并查集；&#xA;初始化 初始时，我们设置每个元素都属于一个单独的集合，表示为一棵只有根节点的树，每个根节点的父亲都设置为自己。&#xA;class Dsu { vector&amp;lt;size_t&amp;gt; parent_; // 表示每个节点的父节点 vector&amp;lt;size_t&amp;gt; size_; // 表示每棵树有多少节点 Dsu(size_t size) : parent_(size), size_(size, 1) { iota(parent_.begin(), parent_.end()); } } 查询 我们只需要沿着树向上移动，直到找到根节点 size_t Dsu::find(size_t x) { return parent_[x] == x ? x : parent_[x]; } 查询时进行路径压缩 查询过程中，经过的每个元素都属于该集合，因此我们可以直接将其连接到根节点，以加快后续查询。 size_t Dsu::find(size_t x) { return parent_[x] == x ? x : parent_[x] = find(parent_[x]); } 合并 要合并两棵树，我们只需要将一棵树的根节点连接到另一棵树的根节点。 void Dsu::Unite(size_t x, size_t y) { parent_(find(x)) = find(y); } 启发式合并 即将节点较小或者深度较小的树连接到另一棵，这里以按节点数合并的实现作为参考:</description>
    </item>
    <item>
      <title>C&#43;&#43; 模板类编译过程中出现“undefined reference to”问题</title>
      <link>http://localhost:1313/posts/tech/cpp_templdate_undefined.zh/</link>
      <pubDate>Tue, 14 Mar 2023 18:35:39 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/cpp_templdate_undefined.zh/</guid>
      <description>问题描述 C++在使用模板(template)类的时候，如果将类的成员函数的声明和实现分别放在.h头文件和.cpp源文件中，编译时会报错undefined reference xxx，找不到对应成员函数。&#xA;起因 .h文件中类的声明为：&#xA;// 线程池，定义成模板类，为了代码的复用 template &amp;lt;typename T&amp;gt; class ThreadPool { ... public: bool append(T *request); ... }; .cpp文件中成员函数的实现为：&#xA;template &amp;lt;typename T&amp;gt; bool ThreadPool&amp;lt;T&amp;gt;::append(T *request) { // 操作工作队列时一定要加锁，因为它被所有线程共享 queue_locker_.lock(); if (work_queue_.size() &amp;gt; max_requests_) { queue_locker_.unlock(); return false; } work_queue_.push_back(request); queue_locker_.unlock(); queue_sta_.post(); return true; } 直接使用g++编译，会报错： 原因分析 template其实是一种类似语法糖的东西，C++中每一个对象所占用的空间大小，是在编译的时候就确定的，在模板类没有真正的被使用之前，编译器是无法知道，模板类中使用模板类型的对象的所占用的空间的大小的。只有模板被真正使用的时候，编译器才知道，模板套用的是什么类型，应该分配多少空间。这也就是模板类为什么只是称之为模板，而不是泛型的缘故。&#xA;即ThreadPool&amp;lt;int&amp;gt;和Thread&amp;lt;HttpConn&amp;gt;是两个不同的类型，其成员函数也是两个不同的成员函数。&#xA;在编译thread_pool.cpp时，编译器会去查找对类Thread&amp;lt;HttpConn&amp;gt;的声明，如果找不到这个声明，那么就报错了。&#xA;解决方案 在成员函数的实现的代码所在的源文件的开头，声明该类，即添加：&#xA;template class ThreadPool&amp;lt;HttpConn&amp;gt;; 或者将函数的实现也写在头文件中（不推荐）。</description>
    </item>
    <item>
      <title>质因数分解</title>
      <link>http://localhost:1313/posts/tech/prime_factorization.zh/</link>
      <pubDate>Mon, 06 Mar 2023 14:32:15 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/prime_factorization.zh/</guid>
      <description>朴素算法 从$[2, \sqrt(N)]$进行遍历&#xA;vector&amp;lt;int&amp;gt; GetFactor(int N) { vector&amp;lt;int&amp;gt; res; for (int i = 2; i * i &amp;lt;= N; ++i) { if (N % i == 0) { while (N % i == 0) { N /= i; } res.push_back(i); } } if (N != 1) { res.push_back(N); } return res; } 朴素算法的证明 首先证明元素均为 $N$ 的素因数：因为当且仅当 N % i == 0 满足时，result 发生变化：储存 $i$，说明此时 $i$ 能整除 $\frac{N}{A}$，说明了存在一个数 $p$ 使得 $pi=\frac{N}{A}$，即 $piA = N$（其中，$A$ 为 $N$ 自身发生变化后遇到 $i$ 时所除的数。我们注意到 result 若在 push $i$ 之前就已经有数了，为 $R_1,,R_2,,\ldots,,R_n$，那么有 N $=\frac{N}{R_1^{q_1}\cdot R_2^{q_2}\cdot \cdots \cdot R_n^{q_n}}$，被除的乘积即为 $A$）。所以 $i$ 为 $N$ 的因子。</description>
    </item>
    <item>
      <title>位运算与集合</title>
      <link>http://localhost:1313/posts/tech/bit_operation.zh/</link>
      <pubDate>Thu, 05 Jan 2023 14:50:46 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/bit_operation.zh/</guid>
      <description>前言 在刷 LeetCode 的时候，我们常常碰到需要枚举同时选择几个元素，或者说枚举选择一个集合的情况，即同时选择 $\lbrace0, 1, 2\rbrace$ 或者 $\lbrace0, 1,3\rbrace$ 等，这里集合中的数字表示要选择的元素的索引。&#xA;通常情况下，我们往往会使用哈希表来表示集合，好处在于可以方便的在 $O(1)$ 时间内确定元素是否处于集合中，坏处则是当我们需要做集合之间的运算，例如求交集或者并集，那么就需要 $O(n)$ 时间才能实现；另一个缺陷就是，当递归函数的可变实参中存在哈希表（或者对哈希表的引用）时，无法通过添加 $cach$ 数组实现记忆化搜索。&#xA;于是，我们需要想一个新的办法来表示集合，由于集合可以由全集（包含所有元素的集合）中每个元素的选或者不选来表示，因此，很容易联想到二进制上每一位的 $0$ 和 $1$，例如 $101 = 5$ 表示集合中只有第 $0$ 个元素和第 $2$ 个元素。&#xA;使用数学化一点的语言，即集合可以以如下方式压缩成二进制下的一个数字：&#xA;$$f(S)=\sum\limits_{i\in S}2^i$$&#xA;其中 $i$ 表示集合中的元素在原数组中的索引。$\lbrace a[0], a[1], a[3]\rbrace$ 即可由 $2^0+2^1+2^3 = 13$ 即二进制数 $1101$ 表示。&#xA;集合与元素 根据上面提到的二进制表示集合的方法，我们可以在 $O(1)$ 的时间内实现集合与元素之间的运算。&#xA;具体运算表格参见灵神的 从集合论到位运算，常见位运算技巧分类总结！。 无需记忆，自己做题的时候很容易就能推导出来。&#xA;集合与集合 集合与集合之间的运算也可以在用二进制数表示集合的情况下，在 $O(1)$ 时间内完成计算。&#xA;具体运算表格同样参见灵神的 从集合论到位运算，常见位运算技巧分类总结！。&#xA;同样无需记忆，自己做题的时候很容易就能推导出来。&#xA;遍历集合 在集合用二进制数 $mask$ 表示的情况下，集合中的元素个数可以由 C++ 库函数 __builtin_popcount(mask) 计算出来。&#xA;设元素范围从 $0$ 到 $n - 1$，挨个判断元素是否在集合 $s$ 中：</description>
    </item>
    <item>
      <title>快速幂与快速乘</title>
      <link>http://localhost:1313/posts/tech/exponentiating-by-squaring.zh/</link>
      <pubDate>Sat, 19 Nov 2022 11:51:26 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/exponentiating-by-squaring.zh/</guid>
      <description>定义 快速幂，二进制取幂（Binary Exponentiation，也称平方法），是一个在 $\Theta(\log n)$ 的时间内计算 $a^n$ 的小技巧，而暴力的计算需要 $\Theta(n)$ 的时间。&#xA;这个技巧也常常用在非计算的场景，因为它可以应用在任何具有结合律的运算中。其中显然的是它可以应用于模意义下取幂、矩阵幂等运算，我们接下来会讨论。&#xA;解释 计算 $a$ 的 $n$ 次方表示将 $n$ 个 $a$ 乘在一起：$a^{n} = \underbrace{a \times a \cdots \times a}_{n\text{ 个 a}}$。然而当 $a,n$ 太大的时侯，这种方法就不太适用了。不过我们知道：$a^{b+c} = a^b \cdot a^c,,,a^{2b} = a^b \cdot a^b = (a^b)^2$。二进制取幂的想法是，我们将取幂的任务按照指数的 二进制表示 来分割成更小的任务。&#xA;过程 首先我们将 $n$ 表示为 2 进制，举一个例子吧：&#xA;$$ 3^{13} = 3^{(1101)_2} = 3^8 \cdot 3^4 \cdot 3^1 $$&#xA;因为 $n$ 有 $\lfloor \log_2 n \rfloor + 1$ 个二进制位，因此当我们知道了 $a^1, a^2, a^4, a^8, \dots, a^{2^{\lfloor \log_2 n \rfloor}}$ 后，我们只用计算 $\Theta(\log n)$ 次乘法就可以计算出 $a^n$。</description>
    </item>
    <item>
      <title>496.next greater element i</title>
      <link>http://localhost:1313/posts/leet/496.next-greater-element-i/</link>
      <pubDate>Fri, 11 Nov 2022 16:45:53 +0800</pubDate>
      <guid>http://localhost:1313/posts/leet/496.next-greater-element-i/</guid>
      <description>Description 496.next-greater-element-i&#xA;Solution We can use monotone stack to traverse nums2, and use unordered_map to store the element in nums1 and corresponding result.&#xA;Code class Solution { public: vector&amp;lt;int&amp;gt; nextGreaterElement(vector&amp;lt;int&amp;gt; &amp;amp;nums1, vector&amp;lt;int&amp;gt; &amp;amp;nums2) { unordered_map&amp;lt;int, int&amp;gt; umap; stack&amp;lt;int&amp;gt; stk; for (int i = 0; i &amp;lt; nums1.size(); i++) { umap.insert({nums1[i], -1}); } stk.push(0); for (int i = 1; i &amp;lt; nums2.size(); i++) { while (!stk.empty() &amp;amp;&amp;amp; nums2[i] &amp;gt; nums2[stk.top()]) { if (umap.</description>
    </item>
    <item>
      <title>496.下一个更大元素I</title>
      <link>http://localhost:1313/posts/leet/496.next-greater-element-i.zh/</link>
      <pubDate>Fri, 11 Nov 2022 16:45:47 +0800</pubDate>
      <guid>http://localhost:1313/posts/leet/496.next-greater-element-i.zh/</guid>
      <description>问题描述 496.下一个更大元素I&#xA;解题思路 本题利用单调栈(monotone stack)来遍历nums2，并且利用unordered_map来存储nums1中元素和对应的结果。&#xA;代码 class Solution { public: vector&amp;lt;int&amp;gt; nextGreaterElement(vector&amp;lt;int&amp;gt; &amp;amp;nums1, vector&amp;lt;int&amp;gt; &amp;amp;nums2) { unordered_map&amp;lt;int, int&amp;gt; umap; stack&amp;lt;int&amp;gt; stk; for (int i = 0; i &amp;lt; nums1.size(); i++) { umap.insert({nums1[i], -1}); } stk.push(0); for (int i = 1; i &amp;lt; nums2.size(); i++) { while (!stk.empty() &amp;amp;&amp;amp; nums2[i] &amp;gt; nums2[stk.top()]) { if (umap.find(nums2[stk.top()]) != umap.end()) { umap[nums2[stk.top()]] = nums2[i]; } stk.pop(); } stk.push(i); } vector&amp;lt;int&amp;gt; res(nums1.size(), -1); for (int i = 0; i &amp;lt; nums1.</description>
    </item>
    <item>
      <title>miniconda 基础教程</title>
      <link>http://localhost:1313/posts/tech/miniconda.zh/</link>
      <pubDate>Fri, 11 Nov 2022 15:55:04 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/miniconda.zh/</guid>
      <description>创建python虚拟环境 安装python指定环境 conda create -n zwyb python=3.9&#xA;安装python指定环境的时候安装相应的包 conda create -n zwyb python=3.9 pandas&#xA;进入指定的环境 conda activate zwyb&#xA;退出当前环境 conda deactive zwyb&#xA;显示所有环境 conda env list&#xA;删除指定的环境 conda env remove -n zwyb&#xA;更换清华源 vim 编辑~/.condarc，将其中内容修改为&#xA;channels: - defaults show_channel_urls: true default_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud 更换pip源，执行 pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple&#xA;关闭启动终端后自动进入conda环境 conda config --set auto_activate_base false</description>
    </item>
    <item>
      <title>monotone stack</title>
      <link>http://localhost:1313/posts/tech/monotone-stack/</link>
      <pubDate>Fri, 11 Nov 2022 15:55:04 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/monotone-stack/</guid>
      <description>Description brief Monotone stack is a stack whose elements(from top to bottom) are (strictly) monotonically increasing or decreasing.&#xA;Monotone increasing stack: the element which is smaller than the element in the top can be pushed into stack, else we will pop the element in the top, until the stack is empty or the element is smaller than the element in the top, then we push the element into the stack. This data structure is usually used for problems to find first element that is larger than certain element.</description>
    </item>
    <item>
      <title>单调栈</title>
      <link>http://localhost:1313/posts/tech/monotone-stack.zh/</link>
      <pubDate>Fri, 11 Nov 2022 15:54:59 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/monotone-stack.zh/</guid>
      <description>问题描述 简述 单调栈(monotone stack)是指栈内元素(栈顶到栈底)都是(严格)单调递增或者递减的栈。&#xA;单调递增栈(从栈顶到栈底)：只有比栈顶小的才能入栈，否把栈顶元素弹出，直到栈为空或者或者待处理的元素小于栈顶元素，将元素入栈，适用于求解第一个大于某元素的数的情况；&#xA;单调递减栈，与递增栈相反，适用于求解第一个小于某位置元素的数；&#xA;判断方法 单调递增/递减栈一般根据出栈后顺序来决定，例如栈内顺序[1, 2, 6]，出栈后顺序[6, 2, 1]，这就是单调递减栈。&#xA;哨兵技巧 对于有些时候，如果会用到数组的全部元素，即栈中的元素最后都要出栈，那么很可能因为没有考虑边界而无法通过。所以我们可以使用哨兵法。&#xA;例如在{1, 3, 4, 5, 2, 9, 6}末尾添加一个-1作为哨兵，变成了 {1, 3, 4, 5, 2, 9, 6, -1}，这种技巧可以简化代码逻辑。&#xA;例题 </description>
    </item>
    <item>
      <title>unbounded knapsack problem</title>
      <link>http://localhost:1313/posts/tech/unbounded-knapsack-problem/</link>
      <pubDate>Tue, 04 Oct 2022 01:33:48 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/unbounded-knapsack-problem/</guid>
      <description>Description Unbounded Knapsack Problem&#xA;There are $N$ kinds of items and a knapsack with the capacity of $V$, each item has unlimited pieces available.&#xA;The volume of the $i$-th item is $v_i$, and value is $w_i$. Please solve which items can be put into the pack so that the value is the greatest and the total volume of these items dosen&amp;rsquo;t exceed the capacity of the pack.&#xA;Solution It&amp;rsquo;s a classic problem of dynamic programming and knapsack problem.</description>
    </item>
    <item>
      <title>完全背包问题</title>
      <link>http://localhost:1313/posts/tech/unbounded-knapsack-problem.zh/</link>
      <pubDate>Mon, 03 Oct 2022 13:50:44 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/unbounded-knapsack-problem.zh/</guid>
      <description>问题描述 完全背包问题&#xA;有$N$件物品和一个容量是$V$的背包，每件物品都有无限件可用。&#xA;第$i$种物品的体积是$v_i$，价值是$w_i$。求解将哪些物品装入背包，可使这些物品总体积不超过背包容量，且总价值最大。&#xA;解题思路 内层嵌套循环 01背包问题 每样物品只能使用一件，而针对完全背包问题，我们只需要在内层有关体积的循环中，再添加一层循环，枚举一共使用了多少件物品$i$即可。&#xA;for (int i = 1; i &amp;lt;= n; i++) { for (int j = m; j &amp;gt;= v[i]; j--) { for (k = 1; k * v[i] &amp;lt;= j; k++) { dp[j] = max(dp[j], dp[j - k * v[i] + k * w[i]); } } } 更改遍历方向 在01背包问题中，我们内层关于体积的循环，是从大到小的，这是为了保证在比较max(dp[j], dp[j - v[i]] + w[i])时，使用的是上一次i循环的数值；&#xA;而在完全背包问题中，内层关于体积的循环，修改成从小到大即可，此时dp = max(dp[j], dp[j - v[i]] + w[i])中，dp[j - v[i]] + w[i]使用的就是本次i循环中的数值，而i循环中,dp[j - v[i]] = max(dp[j - v[i]], dp[(j - v[i]) - v[i]] + w[i]),依次往前递推，总能找到那个最大值dp[j - k * v[i]] + k * w[i]。</description>
    </item>
    <item>
      <title>01背包问题</title>
      <link>http://localhost:1313/posts/leet/01-pack-problem.zh/</link>
      <pubDate>Sat, 01 Oct 2022 15:08:30 +0800</pubDate>
      <guid>http://localhost:1313/posts/leet/01-pack-problem.zh/</guid>
      <description>问题描述 01背包问题 有$N$件物品和一个容量是$V$的背包，每件物品只能使用一次。&#xA;第$i$件物品的体积是$v_i$，价值是$w_i$，求解将哪些物品装入背包，可使这些物品总体积不超过背包容量，并且总价值最大。&#xA;解题思路 动态规划的经典例题，首先考虑dp[i][j]的含义，这里i表示只考虑前i个物品(i从$1\sim N$)，dp[i][j]表示总体积为j的情况下，考虑前i个物品时，背包里的物品的最大价值。&#xA;可以分成两种情况考虑dp[i][j]的递推关系：&#xA;第i个物品不在背包中时，dp[i][j] = dp[i - 1][j] 此时只有前i - 1个物品，背包中物品体积仍为j。 第i个物品在背包中时，dp[i][j] = dp[i - 1][j - v[i]] + w[i] 前i - 1个物品的体积为j - v[i]。 初始化，显然dp[0][0] = 0。&#xA;根据递推关系和初始化条件写for循环遍历即可。&#xA;代码 #include &amp;lt;algorithm&amp;gt; #include &amp;lt;iostream&amp;gt; #include &amp;lt;string&amp;gt; using namespace std; const int N = 1010; // 体积不超过1000， 物品件数也不超过1000 int main() { int n, m; // n为物品数量，m为背包体积 cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m; int dp[N][N] = {0}; int v[N] = {0}; // 体积 int w[N] = {0}; // 价值 for (int i = 1; i &amp;lt;=n; i++) cin &amp;gt;&amp;gt; v[i] &amp;gt;&amp;gt; w[i]; for (int i = 1; i &amp;lt;= n; i++) { for (int j = 1; j &amp;lt;= m; j++) { dp[i][j] = dp[i - 1][j]; if (j &amp;gt;= v[i]) // 当前总体积肯定不能小于v[i]，如果小于的话，第i个物品不能放 dp[i][j] = max(dp[i][j], dp[i - 1][j - v[i]] + w[i]); } } // int res = 0; // for (int j = 1; j &amp;lt;=m; j++) { // res = max(res, dp[n][j]); // 不需要遍历，直接输出dp[n][m]即可 // } cout &amp;lt;&amp;lt; dp[n][m] &amp;lt;&amp;lt; endl; return 0; } 优化 分析上面的代码，实际上dp[i][j]递推时只会用到dp[i - 1][j]，而不会用到dp[i - 2][j], dp[i - 3][j]等，因此dp数组实际上只需要一维即可，索引为当前总体积。</description>
    </item>
    <item>
      <title>01 kanpsack problem</title>
      <link>http://localhost:1313/posts/leet/01-pack-problem/</link>
      <pubDate>Sat, 01 Oct 2022 15:08:23 +0800</pubDate>
      <guid>http://localhost:1313/posts/leet/01-pack-problem/</guid>
      <description>Description 01-pack-problem&#xA;There are $N$ items and a pack with capacity of $V$, and each item can only be used once.&#xA;The volume of the $i$-th item is $v_i$, and vaule is $w_i$. Please solve which items can be put into the pack so that the value is the greatest and the total volume of these items dosen&amp;rsquo;t exceed the capacity of the pack.&#xA;Solution It&amp;rsquo;s a classic problem of dynamic programming.</description>
    </item>
    <item>
      <title>Dynamic Programming</title>
      <link>http://localhost:1313/posts/tech/dynamic-programming/</link>
      <pubDate>Thu, 29 Sep 2022 16:25:12 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/dynamic-programming/</guid>
      <description>Description Usually, One-dimensional dynamic planning problem, the parameter is always $n$, the result is similar to number sequence $a_n$, or $f(n)$($f$ can be viewed as function or corresponding relationship). At the same time, there will be certain corresponding relationship between $a_n$ and $a_{n - 1}, a_{n - 2}&amp;hellip;a_{1}$, such as $a_n = a_{n-1} + a_{n-2}$(fibonacci sequence).&#xA;Solution Number sequence can be corresponded with array in programming language such as C++. If you find the recursive relationship among number sequence, you can write traversal code using for loop to get the answer.</description>
    </item>
    <item>
      <title>一维动态规划-基础版</title>
      <link>http://localhost:1313/posts/tech/dynamic-programming.zh/</link>
      <pubDate>Wed, 28 Sep 2022 19:23:30 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/dynamic-programming.zh/</guid>
      <description>问题描述 一般来说，一维动态规划的问题，其输入的参数一般是$n$，而所求结果有点像数列$a_n$，或者说$f(n)$($f$可以认为是函数或者说对应关系)，同时$a_n$与之前的$a_{n-1},a_{n-2},&amp;hellip;a_{1}$有一个确定的对应的关系，例如$a_n = a_{n-1} + a_{n-2}$(斐波那契数列)&#xA;解题步骤 数列即可与编程语言中的数组对应起来，在找到数列之间的迭代关系时，即可编写for循环来求解。&#xA;例题 509.斐波那契数 509.斐波那契数-题解 70.爬楼梯 70.爬楼梯-题解 746.使用最小花费爬楼梯 746.使用最小花费爬楼梯-题解 343.整数拆分 343.整数拆分-题解 62.不同路径 62.不同路径-题解 63.不同路径II 63.不同路径II-题解 </description>
    </item>
    <item>
      <title>Math_test</title>
      <link>http://localhost:1313/posts/tech/math_test/</link>
      <pubDate>Mon, 26 Sep 2022 11:40:26 +0800</pubDate>
      <guid>http://localhost:1313/posts/tech/math_test/</guid>
      <description>math_test 中文测试 $a_b$ $$a_b + c_d$$&#xA;aaa</description>
    </item>
  </channel>
</rss>
